{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code to find the most suitable K value for the KNN filling algorithm\n",
    "Since Logistic regression performs and worst among all algorithm, we don't use it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "# Cross Validation Classification Accuracy\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing \n",
    "from sklearn.impute import KNNImputer\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "#import faiss\n",
    "from numpy import isnan\n",
    "#import matplotlib.pyplot as plot\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn import tree\n",
    "import statistics\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# plotting errorbar graph for visual representation of the performance of the classifiers\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import Affine2D\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "import shutil\n",
    "import os\n",
    "from os import path\n",
    "import ipynb.fs.full.our_functions_library as flib\n",
    "from our_evaluate_sepsis_score import evaluate_performance\n",
    "#from our_functions_library import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: (77726, 43)\n",
      "Patient id size: 2000\n"
     ]
    }
   ],
   "source": [
    "# Global initialization, get all the data from file and generate all the needed variable\n",
    "filename = 'raw_data/raw_data_2000.csv' # use raw dataset\n",
    "#filename = 'data.csv' # use raw dataset\n",
    "originalData = read_csv(filename) # read csv data into DataFrame var raw\n",
    "print(\"Data size:\",originalData.shape)\n",
    "Original_Uniq_ID= np.unique(originalData['Patient_id']) \n",
    "Uniq_ID = Original_Uniq_ID.copy()\n",
    "print('Patient id size:',len(Uniq_ID))\n",
    "X_columns = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2','BaseExcess', 'HCO3', 'FiO2', 'pH', \n",
    "             'PaCO2', 'SaO2', 'AST', 'BUN','Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
    "             'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium','Bilirubin_total', 'TroponinI', 'Hct', \n",
    "             'Hgb', 'PTT', 'WBC','Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2','HospAdmTime',\n",
    "             'ICULOS', 'Patient_id', 'time']\n",
    "y_columns = ['Patient_id', 'SepsisLabel']\n",
    "\n",
    "# To test if these 3 columns is useful\n",
    "# originalData = originalData.drop(['Unit1', 'Unit2', 'EtCO2'], axis=1)\n",
    "# X_columns.remove('Unit1')\n",
    "# X_columns.remove( 'Unit2')\n",
    "# X_columns.remove( 'EtCO2')\n",
    "\n",
    "# Initialize the empty array X_train, X_test, y_train, y_test\n",
    "X_train = pd.DataFrame(columns = X_columns)\n",
    "X_test = pd.DataFrame(columns = X_columns)\n",
    "y_train = pd.DataFrame(columns = y_columns)\n",
    "y_test = pd.DataFrame(columns = y_columns)\n",
    "# Below are the lists for KNN results\n",
    "\n",
    "KNN_UtilityScore_mean = []\n",
    "KNN_UtilityScore_std = []\n",
    "\n",
    "KNN_F1Score_mean = []\n",
    "KNN_F1Score_std = []\n",
    "\n",
    "KNN_auroc_mean = []\n",
    "KNN_auprc_mean = []\n",
    "\n",
    "KNN_accuracy_mean = []\n",
    "KNN_accuracy_std = []\n",
    "\n",
    "KNN_positiveprediction_mean = []\n",
    "KNN_baseline_mean = [ ]\n",
    "\n",
    "KNN_total_Time= [ ]\n",
    "\n",
    "\n",
    "fillmethod =\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They are the same. Uniq id hasn't been shuffled, and it will be shuffeld now.\n",
      "The original uniq id set is:\n",
      " [ 2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Uniq id:************************************\n",
      "The fixed shuffelld id set, it should be 211 275 153 189 184 110 124  49 345...\n",
      " [1530  469  774  749 1165 1780 1525  922 1280  509 1689  298  616 1551\n",
      " 1840  327 1865  752 1031]\n"
     ]
    }
   ],
   "source": [
    "#This block will shuffle the id sets of patients in a fix manner, so for every time you run the code, the dataset and trainset are always the same.\n",
    "seed = 2\n",
    "random.seed(seed)\n",
    "if(np.array_equal(Original_Uniq_ID,Uniq_ID) ):\n",
    "    print(\"They are the same. Uniq id hasn't been shuffled, and it will be shuffeld now.\")   \n",
    "    random.shuffle(Uniq_ID)# randomly sorted the patient IDs    \n",
    "else:\n",
    "    print(\"They are not the same. Uniq_id has already been shuffled.\")    \n",
    "print(\"The original uniq id set is:\\n\",Original_Uniq_ID[1:20])\n",
    "print(\"Uniq id:************************************\")\n",
    "print(\"The fixed shuffelld id set, it should be 211 275 153 189 184 110 124  49 345...\\n\",Uniq_ID[1:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fill the missing data with one function\n",
    "# print(filename)\n",
    "# #print(originalData)\n",
    "# if (originalData.isnull().values.any()):\n",
    "#     print('There is data missing in the original data set')\n",
    "# dataByPatient = originalData.groupby('Patient_id') # data grouped by Patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearAllDatasets():\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    if not X_train.empty: \n",
    "        X_train = X_train[0:0]\n",
    "    if not X_test.empty:\n",
    "        X_test = X_test[0:0]\n",
    "    if not y_train.empty:\n",
    "        y_train = y_train[0:0]\n",
    "    if not y_test.empty:\n",
    "        y_test = y_test[0:0]\n",
    "        \n",
    "def KNN_reset():\n",
    "    #KNN with different K size, \n",
    "    KNN_UtilityScore_mean.clear()\n",
    "    KNN_UtilityScore_std.clear()\n",
    "    KNN_F1Score_mean.clear()\n",
    "    KNN_F1Score_std.clear()\n",
    "    KNN_auroc_mean.clear()\n",
    "    KNN_auprc_mean.clear()\n",
    "    KNN_accuracy_mean.clear()\n",
    "    KNN_accuracy_std.clear()\n",
    "    KNN_positiveprediction_mean.clear()\n",
    "    KNN_baseline_mean.clear()\n",
    "    KNN_total_Time.clear()\n",
    "    \n",
    "def generateTrainDataSet(patienIds):\n",
    "    global X_train, y_train\n",
    "    for i in patienIds:\n",
    "#     print('Patient_id',i,':\\n',dataByPatient.get_group(i),'\\n')\n",
    "        X_train = X_train.append(dataByPatient.get_group(i).loc[:, X_columns])\n",
    "        y_train = y_train.append(dataByPatient.get_group(i).loc[:, y_columns])\n",
    "    return X_train, y_train\n",
    " \n",
    "def generateTestDataSet(patienIds):\n",
    "    global X_test, y_test\n",
    "    for i in patienIds:\n",
    "#     print('Patient_id',i,':\\n',dataByPatient.get_group(i),'\\n')\n",
    "        X_test = X_test.append(dataByPatient.get_group(i).loc[:, X_columns])\n",
    "        y_test = y_test.append(dataByPatient.get_group(i).loc[:, y_columns]) \n",
    "    return X_test, y_test\n",
    "\n",
    "# def CalculateSOFAScore(X_train_impute, X_test_impute):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for K-fold algorithm, Before this step the missing data has been filled, \n",
    "def KFold_patient(model, KforKFold=10,KforKNN=5, fillmethod=\"\"):\n",
    "    start = time.time()# time indicator for how long the Kfold func takes\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    print(\"K Fold of \",KforKFold ,\" folds with KNN =\",KforKNN)\n",
    "    \n",
    "    # initialisation of the array for storing the different intermediate results\n",
    "    accuracy_model = []\n",
    "    F1Score_model = []\n",
    "    baseline_model= []\n",
    "    auroc_model = []\n",
    "    auprc_model = []\n",
    "    physio_accuracy_model = []\n",
    "    f_measure_model = []\n",
    "    utility_score_model = []\n",
    "    mean_train = 0\n",
    "    positivepredictions = []\n",
    "    #The unique id sets have been created and shuffled in a fix manner in the third block, you can just use it here and no more any other manipulation\n",
    "    idSets = np.array_split(Uniq_ID, KforKFold)# divide the ids into K groups\n",
    "    #print(\"Patients number: \", len(Uniq_ID)) #print('idSets arrays',idSets)\n",
    "    #This for loop is for Kfold, calculating the results for K times\n",
    "    for i in range(KforKFold):\n",
    "        start1 = time.time()\n",
    "        clearAllDatasets()\n",
    "#         X_train, X_test, y_train, y_test = flib.clearAllDatasets(X_train, X_test, y_train, y_test) #first clear all the datasets\n",
    "        print(\"for the\",i+1,\"th iteration\",idSets[i])   \n",
    "        t1 = time.time()\n",
    "        X_test,y_test = generateTestDataSet(idSets[i])\n",
    "        print(\"Time for splitting id to test:\", round(time.time()- t1,2))\n",
    "        \n",
    "        t2= time.time()\n",
    "        for j in range(KforKFold):\n",
    "            if j != i:\n",
    "                 X_train, y_train = generateTrainDataSet(idSets[j])\n",
    "        print(\"Time for splitting id to train:\", round(time.time()- t2,2))\n",
    "\n",
    "        #printDataset()\n",
    "        #Now the train and test dataset is generated\n",
    "        #we can begin to train the model wit the training set and evaaulate the performance with the test sett   \n",
    "#         X_train = X_train.drop('time', 1) X_test = X_test.drop('time', 1)\n",
    "        X_train=X_train.astype('float64')\n",
    "        X_test=X_test.astype('float64')    \n",
    "        YTest_copy = y_test  # variable of joining the filled data (X) and Y (Train_output) \n",
    "        patientID_ytest = y_test['Patient_id']\n",
    "        y_train = y_train.drop('Patient_id', 1)\n",
    "        y_test = y_test.drop('Patient_id', 1)      \n",
    "        y_train=y_train.astype('float64')\n",
    "        y_test=y_test.astype('float64')\n",
    "        #print('YTest',YTest_copy.head())\n",
    "        \n",
    "        #fill the missing data\n",
    "        if X_train.isnull().values.any() or X_test.isnull().values.any() :\n",
    "            print(\"X_train or X_test contains NaN values, KNN/mean is performed.\")\n",
    "            #if there is missing value\n",
    "            X_train_impute, X_test_impute, fillmethod = flib.KNNfilling(X_train, X_test, KforKNN, fillmethod)\n",
    "            #X_train_impute, X_test_impute,fillmethod = flib.MeanFilling(X_train,X_test, fillmethod)\n",
    "            #check the missing data   \n",
    "            if np.isnan(X_train_impute).any() or np.isnan(X_test_impute).any() :\n",
    "                print(\"X_train_impute or X_test_impute still contains NaN values\")        \n",
    "            else:\n",
    "                print(\"X_train_impute or X_test_impute have all been filled \")  \n",
    "        else:\n",
    "            print(\"X_train or X_test have all been filled \")\n",
    "            X_train_impute = X_train\n",
    "            X_test_impute = X_test\n",
    "                 \n",
    "        #Scale the data， uncomment this part for logistic regression only, in other case, put them in comment\n",
    "        model_name = type(model).__name__\n",
    "        if (model_name == 'LogisticRegression'):\n",
    "            print(\"scaled!\")\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            scaler.fit(X_train_impute)\n",
    "            X_train_impute = scaler.transform(X_train_impute)\n",
    "            X_test_impute = scaler.transform(X_test_impute)\n",
    "\n",
    "        #fit the model and predict\n",
    "        model.fit(X_train_impute, y_train)\n",
    "        y_predicted = model.predict(X_test_impute)   \n",
    "        y_predicted_probobility = model.predict_proba(X_test_impute) \n",
    "        #transfer the outpu and evalute it\n",
    "        y_labels = y_test.astype(int).to_numpy()\n",
    "        y_predicted = y_predicted.astype(int)\n",
    "        y_predicted_probobility =  y_predicted_probobility[:,1].round(4)\n",
    "        #print(y_labels)      \n",
    "        auroc, auprc, physio_accuracy, f_measure, utility_score = evaluate_performance(y_labels, y_predicted, y_predicted_probobility,patientID_ytest)\n",
    "#         print(\"\\nauroc\",round(auroc,4),\"auprc\",round(auprc,4),\"util_accuracy\",round(accuracy1,4))\n",
    "#         print(\"f_measure\",round(f_measure,4),\"utility_score\",round(utility_score,4))  \n",
    "        auroc_model.append(round(auroc,4))\n",
    "        auprc_model.append(round(auprc,4))\n",
    "        physio_accuracy_model.append(round(physio_accuracy,4))\n",
    "        f_measure_model.append(round(f_measure,4))\n",
    "        utility_score_model.append(round(utility_score,4))\n",
    "        positivepredictions.append(np.sum(y_predicted))\n",
    "\n",
    "        num_rows= X_test_impute.shape[0]\n",
    "        scores = np.zeros(num_rows).astype('float64')# score parameter:output from get_sepsis_score\n",
    "        labels = np.zeros(num_rows).astype('float64')\n",
    "        #WriteToFiles(X_train_impute,YTest_copy,i, fillmethod)\n",
    "        #CalcMean_Std(X_train_impute)\n",
    "        #take down the results\n",
    "        accuracy_model.append((accuracy_score(y_test, y_predicted, normalize=True)*100).round(2))\n",
    "        F1Score_model.append((f1_score(y_test, y_predicted)*100).round(2))\n",
    "        baseline_model.append(round( (1 - float(y_test.mean()) )*100 , 2 ))\n",
    "        print(\"\\ny_test size:\",y_test.shape, '1´s in y_test',y_test.sum())\n",
    "        #baseline_model.append(((1-y_test.mean())*100).round(2))\n",
    "        print(\"The number of 1 (SepsisLabel) in this prediction: \", np.sum(y_predicted))\n",
    "        end1 = time.time()\n",
    "        print(\"Time spent in this KFold iteration\",round(end1-start1,2),\"sec.\\n\")\n",
    "        print(\"******************************************************************\")\n",
    "    print('Accuracy model:', accuracy_model)\n",
    "    print('F1_score model:', F1Score_model)\n",
    "    print('Baseline model:', baseline_model)\n",
    "    \n",
    "    print(\"\\nEvaluation parameters of the utiltiy evaluation function:\")\n",
    "    print('auroc of model:', auroc_model)\n",
    "    print('auprc of model:', auprc_model)\n",
    "    print('Utility accuracy of model:', accuracy_model)\n",
    "    print('utility F1 of model:', f_measure_model)\n",
    "    print('Utility score of model:', utility_score_model)\n",
    "    \n",
    "    KNN_UtilityScore_mean.append(np.mean(utility_score_model))\n",
    "    KNN_UtilityScore_std.append(np.std(utility_score_model))\n",
    "    \n",
    "    KNN_F1Score_mean.append(np.mean(f_measure_model))\n",
    "    KNN_F1Score_std.append(np.std(f_measure_model))\n",
    "    \n",
    "    KNN_auroc_mean.append(np.mean(auroc_model))\n",
    "    KNN_auprc_mean.append(np.mean(auprc_model))\n",
    "    \n",
    "    KNN_accuracy_mean.append(np.mean(physio_accuracy_model))\n",
    "    KNN_accuracy_std.append(np.std(physio_accuracy_model))\n",
    "    \n",
    "    KNN_positiveprediction_mean.append(np.mean(positivepredictions))\n",
    "    KNN_baseline_mean.append(np.mean(baseline_model))\n",
    "    \n",
    "    totalTime=round(time.time()- start,2)\n",
    "    KNN_total_Time.append(totalTime)\n",
    "    \n",
    "    print(\"\\nTotal Time spent in  KFold function\",totalTime,\"sec.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def displayCurrentResult(KforKNNstart,KforKNNend):\n",
    "    print(\"KNN_UtilityScore_mean\",KNN_UtilityScore_mean)\n",
    "    print(\"KNN_UtilityScore_std\",KNN_UtilityScore_std)\n",
    "    print(\"KNN_F1Score_mean\",KNN_F1Score_mean)\n",
    "    print(\"KNN_F1Score_std\",KNN_F1Score_std)\n",
    "    print(\"KNN_auroc_mean\",KNN_auroc_mean)\n",
    "    print(\"KNN_auprc_mean\",KNN_auprc_mean)\n",
    "    print(\"KNN_accuracy_mean\",KNN_accuracy_mean)\n",
    "    print(\"KNN_accuracy_std\",KNN_accuracy_std)\n",
    "    print(\"KNN_positiveprediction_mean\",KNN_positiveprediction_mean)\n",
    "    print(\"KNN_baseline_mean\",KNN_baseline_mean)        \n",
    "    print(len(KNN_accuracy_mean))\n",
    "    print(len(KNN_accuracy_std))\n",
    "    print(len(KNN_F1Score_mean))\n",
    "    print(len(KNN_F1Score_std))\n",
    "    print(len(KNN_positiveprediction_mean))\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_UtilityScore_mean,\"Mean Utility Score vs K\",xlabel='K',ylabel=\"mean Utility Score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_UtilityScore_std,\"std Utility Score vs K\",xlabel='K',ylabel=\"std Utility Score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_F1Score_mean,\"Mean F1 score vs K\",xlabel='K',ylabel=\"Mean F1 score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_F1Score_std,\"Std F1 score vs K\",xlabel='K',ylabel=\"Std F1 score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_accuracy_mean,\"Mean Accuracy vs K\",xlabel='K',ylabel=\"Mean Accuracy\")      \n",
    "def findBestKforKNN(model, KforKFold=10,KforKNNstart=1,KforKNNend=10, stepsize=5):\n",
    "    if(KforKNNend<=1):\n",
    "        print(\"K must be a interger larger than 1\")\n",
    "        return\n",
    "    KNN_reset()\n",
    "    step=stepsize\n",
    "    for i in range(KforKNNstart,KforKNNend+1,step) : \n",
    "        print(\"KNN of K = \",i)    \n",
    "        KFold_patient(model,10,i)\n",
    "    print(\"Now all the training is finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is how to train the model\n",
    "#logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='saga', max_iter=1000,penalty='l1')\n",
    "logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='lbfgs', max_iter=1000)\n",
    "decisionTreeModel = tree.DecisionTreeClassifier(random_state=2)\n",
    "randomForestModel = RandomForestClassifier(random_state=2)\n",
    "XGBoostModel = XGBClassifier(random_state=2)\n",
    "#AdaBoostModel = AdaBoostClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data/raw_data_2000.csv\n",
      "Data isn´t all filled before K-Fold Func\n"
     ]
    }
   ],
   "source": [
    "#fill the missing data with one function\n",
    "print(filename)\n",
    "#print(originalData)\n",
    "if (originalData.isnull().values.any()):\n",
    "    print('Data isn´t all filled before K-Fold Func')\n",
    "    data=originalData\n",
    "#data,fillmethod = flib.linearFillingAll(originalData,1, True)#forwardfilling + fill other missing data with 0\n",
    "dataByPatient = data.groupby('Patient_id') # data grouped by Patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oke\n"
     ]
    }
   ],
   "source": [
    "model_name= decisionTreeModel.__class__.__name__\n",
    "if (model_name == 'DecisionTreeClassifier'):\n",
    "    print(\"oke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(\"Logistic Regression\")\n",
    "#KFold_patient(decisionTreeModel,10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Decision tree\")\n",
    "#KFold_patient(randomForestModel,10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findBestKforKNN(logisticRegressionModel,10,1,10)\n",
    "# findBestKforKNN(XGBoostModel,10,110,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN of K =  1\n",
      "K Fold of  10  folds with KNN = 1\n",
      "for the 1 th iteration [1367 1530  469  774  749 1165 1780 1525  922 1280  509 1689  298  616\n",
      " 1551 1840  327 1865  752 1031 1089  714  291   68 1735  404 1285 1389\n",
      " 1971 1582 1609 1217  499 1120  324  544 1994 1346  501  651 1586  927\n",
      "  778  503 1450 1566 2000 1835 1194  656  387 1009  704 1248 1429 1424\n",
      "  745  266  429  542 1932 1361 1011  839 1220 1554  567 1252  281  196\n",
      " 1413 1386 1416  128  176  875  724  638  479  259  793 1934  817  869\n",
      " 1898  211 1691  306 1235  670  285  853  552 1434 1576  368  162  314\n",
      "  418 1322 1316 1170  696 1921 1976  573 1763 1123 1333  729 1845 1634\n",
      "  267 1863 1095  108  379 1453  312 1229 1830 1886  708 1232 1082 1121\n",
      " 1606 1068  840 1874  375 1883 1838  748 1318  975 1069  871 1732   87\n",
      " 1500 1523 1022 1837  134  182 1514 1065 1967   39 1510 1019 1214  543\n",
      " 1710 1336  821 1038 1908 1399  895  944  398  153 1193  384  599 1086\n",
      "  199  156 1457  245 1795 1478 1144  717 1066  661  352  549  984  340\n",
      "  168 1565 1059   59 1131  891  207 1085  898  422 1782  178 1345 1283\n",
      "  251 1529 1199  365]\n",
      "Time for splitting id to test: 0.61\n",
      "Time for splitting id to train: 15.82\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (8053, 1) 1´s in y_test SepsisLabel    144.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  199\n",
      "Time spent in this KFold iteration 1005.88 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 2 th iteration [ 865 1982  279 1671  780   85  344  837 1436 1136  226  673 1989 1629\n",
      "  926 1430  732 1157  175  463 1181  210 1738 1603 1172  873  483  633\n",
      "  590 1862 1422  630  920 1203  184 1063  827 1139  893  967 1184    3\n",
      "  396 1790  363  163  304 1777  171  776  332   71  812  986 1409 1643\n",
      " 1325   62 1868  710   15  403 1779 1919  834 1635 1698 1993 1027 1204\n",
      " 1896  901  808   16 1535  874 1601   34  755  855  386  715 1133 1118\n",
      " 1726  980 1767 1766 1996  716  706 1304 1661  578  458  136 1084 1648\n",
      " 1099  636 1489 1234  507 1079  947  795  796 1460  667 1498  741  771\n",
      "  887 1511 1153   14 1844 1415 1368  626 1972 1753  366 1265  581  103\n",
      " 1448 1770  685 1480 1309 1659  424  410 1504  224 1889 1797  744 1245\n",
      " 1438   48  734 1692 1975  565 1881 1352  200  260 1173 1748  942 1387\n",
      " 1155  841  884 1138  112 1114  143  328  269 1003 1969  786  886 1926\n",
      "  299  697  798    5 1869  600  760 1590 1195 1137 1196  617 1334 1341\n",
      "  388  486 1823  923 1276 1013  198  772 1621  577 1477  395 1134  265\n",
      "  856  982  132 1080]\n",
      "Time for splitting id to test: 0.61\n",
      "Time for splitting id to train: 15.97\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (8176, 1) 1´s in y_test SepsisLabel    176.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  359\n",
      "Time spent in this KFold iteration 1219.31 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 3 th iteration [ 727   90  576 1608 1370   99 1307  650 1518 1149 1358 1515    1  433\n",
      "  978 1973 1604  644  597 1602  556  824 1704 1824  787 1855  897  459\n",
      "  611 1098  605 1728  217 1764 1502 1178  592 1593 1673  383 1658  289\n",
      " 1485 1268  450  500 1570  628 1161  864  454 1903  345  836 1509  818\n",
      "  555  794   67  161 1653 1037 1110 1093  319  339 1186   91  317  603\n",
      "  293  756 1522   45  566  728 1291 1665 1207  138  879  115  378 1841\n",
      " 1443 1407 1961 1462 1320  351 1125 1561 1528 1912 1496 1427 1162 1209\n",
      "  504  726  647  335  255  593  220  172  882 1619   20 1949 1032  421\n",
      " 1524 1686  792 1700 1010 1806  235   92  814  308  559 1541  591  759\n",
      "    8  694 1420 1815  305 1721  493  367 1000  671  141  910   76  888\n",
      "  885 1472 1929  915 1050 1210 1421  563 1091  517 1962  811  107 1997\n",
      "  122 1225   30 1688  160  835 1227 1918  797  234 1296  999  813  346\n",
      " 1963  619 1397  316 1364  129 1096   80 1706 1553  767   28  294  300\n",
      " 1249 1533  934  496 1616 1379  843 1832  147  181  474   78  125 1974\n",
      " 1946 1057  832 1733]\n",
      "Time for splitting id to test: 0.63\n",
      "Time for splitting id to train: 15.87\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (8142, 1) 1´s in y_test SepsisLabel    180.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  434\n",
      "Time spent in this KFold iteration 1100.15 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 4 th iteration [ 313  119 1623 1230   23 1392  960  190  202  758   86  900  223 1146\n",
      " 1537 1858  497  863  203  185 1018 1992 1998    2  166  914  659  602\n",
      "  273  408  244  480  601  215  231  553 1105  852  381 1923  935  376\n",
      "  587 1774 1985   88 1012 1714  498 1503  582 1787 1741  342  950  336\n",
      " 1847  229 1683  589  655 1684    6 1253  892  688  338 1694   53 1233\n",
      " 1159 1828   32 1951 1746  972   97 1742  242 1842  963 1246 1660  540\n",
      "   83 1948 1250  831 1978 1376 1724 1750 1825  118  959  731 1925  849\n",
      " 1531  411   12 1423 1877  921  711  663 1260  415  585 1557 1035 1224\n",
      " 1536 1810 1758 1410  179  939  681  240 1879 1849  880 1697 1650  713\n",
      " 1293  464  400 1185  466  534 1369  754 1051 1455 1546 1873  676 1323\n",
      " 1591 1705  518  113  866  371 1581 1017 1411  878 1237  848  680 1970\n",
      " 1014  535 1550 1707 1668 1312  254 1587  905 1743 1127 1167  561   25\n",
      " 1693  437   29  993  985 1168 1876  769 1679  990  276 1517 1385 1649\n",
      " 1348  482  453  257  646  584  423 1044 1400 1757  723  258 1512 1428\n",
      "  360  131  609 1786]\n",
      "Time for splitting id to test: 0.61\n",
      "Time for splitting id to train: 17.06\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (7791, 1) 1´s in y_test SepsisLabel    167.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  315\n",
      "Time spent in this KFold iteration 1308.39 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 5 th iteration [1479  457  664  614 1771  451 1289 1995 1776   55 1100  948  471  940\n",
      " 1300 1202 1239 1187 1340 1213 1765  530  539   54  946  668 1574 1101\n",
      " 1641   82  416 1952 1426  106 1259  564 1549  249 1088  612  114  902\n",
      " 1716  413  225 1151  580  253   42   21  302 1221 1864 1943  847 1589\n",
      " 1667 1560   17   47  629 1475  187 1292  246  430  439 1676  789  625\n",
      " 1197  924 1596 1269 1256 1192 1573  548 1188 1290 1783 1223 1126  445\n",
      " 1577   46   27  154  615 1674 1506  490 1470 1113  652  815 1680  357\n",
      " 1567  624 1490  369  621 1174 1363  349  783 1999  570 1272 1270 1534\n",
      "  677 1799  318   35  144  965  448  140  687  695 1578  554 1028 1271\n",
      " 1654  781  303  662 1299 1164 1613 1311  248  330  212 1543 1094 1303\n",
      "   43  491   31 1687 1702  227 1007 1294  472  722   72  595 1247 1968\n",
      "  533 1501 1406  374  104 1826  528  237 1652 1154 1355  397   56 1891\n",
      " 1775 1236 1129  618   93  908 1822 1176  546 1412 1343  247  221 1258\n",
      "  390 1024  405 1006 1228 1624  447 1484  401 1645  637 1902  142  256\n",
      "  682 1135 1773 1305]\n",
      "Time for splitting id to test: 0.63\n",
      "Time for splitting id to train: 14.91\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (8060, 1) 1´s in y_test SepsisLabel    114.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  407\n",
      "Time spent in this KFold iteration 984.13 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 6 th iteration [ 219  660  241  417 1737 1377  720 1936  606 1894  896 1329  721 1060\n",
      " 1930  233 1599  877 1435  870 1357 1036 1848  487  981 1015  169 1906\n",
      "  916 1183  770 1401 1264 1540  271 1393   38 1579 1924  148 1287  703\n",
      "  525  654  120 1373  406   60   26  201 1132  425 1353 1922  456  966\n",
      "  757 1713  145 1870 1169  962 1605 1966  976  391  522  970 1802  709\n",
      " 1215  917 1723 1778 1238  412 1950 1226  536  683  858  440 1626 1326\n",
      " 1592 1140  933 1388  851  846 1805 1365  568 1882 1990  428 1362  951\n",
      " 1444 1284 1314 1158  402   79 1913  296  460   98 1106  974  538 1808\n",
      " 1440   81 1360  399 1585 1141 1179  213  282  862  470  574 1816 1081\n",
      " 1266  558 1759 1682 1321  613  643  816  268 1302 1984 1977  698  610\n",
      " 1781  773 1755 1663 1785 1583 1047  334 1039 1708  807 1244 1282  441\n",
      "  109  434 1499 1789 1715 1231 1107 1725 1437 1562  761 1598  489 1083\n",
      "  692 1347   13 1119 1872  100 1819 1111 1965  284   63 1145  286  987\n",
      "  133  495  973  102  954  689  189 1552 1539 1820  355  452 1866 1829\n",
      " 1727   19 1580 1611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for splitting id to test: 0.62\n",
      "Time for splitting id to train: 15.77\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n"
     ]
    }
   ],
   "source": [
    "findBestKforKNN(decisionTreeModel,10,1,10)\n",
    "os.system('\\a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCurrentResult(1,9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
