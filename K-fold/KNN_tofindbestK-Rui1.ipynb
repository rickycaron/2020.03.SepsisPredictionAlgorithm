{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code to find the most suitable K value for the KNN filling algorithm\n",
    "Since Logistic regression performs and worst among all algorithm, we don't use it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "# Cross Validation Classification Accuracy\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing \n",
    "from sklearn.impute import KNNImputer\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "#import faiss\n",
    "from numpy import isnan\n",
    "#import matplotlib.pyplot as plot\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn import tree\n",
    "import statistics\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# plotting errorbar graph for visual representation of the performance of the classifiers\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import Affine2D\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "import shutil\n",
    "import os\n",
    "from os import path\n",
    "import ipynb.fs.full.our_functions_library as flib\n",
    "from our_evaluate_sepsis_score import evaluate_performance\n",
    "#from our_functions_library import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: (77726, 43)\n",
      "Patient id size: 2000\n"
     ]
    }
   ],
   "source": [
    "# Global initialization, get all the data from file and generate all the needed variable\n",
    "filename = 'raw_data/raw_data_2000.csv' # use raw dataset\n",
    "#filename = 'data.csv' # use raw dataset\n",
    "originalData = read_csv(filename) # read csv data into DataFrame var raw\n",
    "print(\"Data size:\",originalData.shape)\n",
    "Original_Uniq_ID= np.unique(originalData['Patient_id']) \n",
    "Uniq_ID = Original_Uniq_ID.copy()\n",
    "print('Patient id size:',len(Uniq_ID))\n",
    "X_columns = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2','BaseExcess', 'HCO3', 'FiO2', 'pH', \n",
    "             'PaCO2', 'SaO2', 'AST', 'BUN','Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
    "             'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium','Bilirubin_total', 'TroponinI', 'Hct', \n",
    "             'Hgb', 'PTT', 'WBC','Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2','HospAdmTime',\n",
    "             'ICULOS', 'Patient_id', 'time']\n",
    "y_columns = ['Patient_id', 'SepsisLabel']\n",
    "\n",
    "# To test if these 3 columns is useful\n",
    "# originalData = originalData.drop(['Unit1', 'Unit2', 'EtCO2'], axis=1)\n",
    "# X_columns.remove('Unit1')\n",
    "# X_columns.remove( 'Unit2')\n",
    "# X_columns.remove( 'EtCO2')\n",
    "\n",
    "# Initialize the empty array X_train, X_test, y_train, y_test\n",
    "X_train = pd.DataFrame(columns = X_columns)\n",
    "X_test = pd.DataFrame(columns = X_columns)\n",
    "y_train = pd.DataFrame(columns = y_columns)\n",
    "y_test = pd.DataFrame(columns = y_columns)\n",
    "# Below are the lists for KNN results\n",
    "\n",
    "KNN_UtilityScore_mean = []\n",
    "KNN_UtilityScore_std = []\n",
    "\n",
    "KNN_F1Score_mean = []\n",
    "KNN_F1Score_std = []\n",
    "\n",
    "KNN_auroc_mean = []\n",
    "KNN_auprc_mean = []\n",
    "\n",
    "KNN_accuracy_mean = []\n",
    "KNN_accuracy_std = []\n",
    "\n",
    "KNN_positiveprediction_mean = []\n",
    "KNN_baseline_mean = [ ]\n",
    "\n",
    "KNN_total_Time= [ ]\n",
    "\n",
    "\n",
    "fillmethod =\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They are the same. Uniq id hasn't been shuffled, and it will be shuffeld now.\n",
      "The original uniq id set is:\n",
      " [ 2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Uniq id:************************************\n",
      "The fixed shuffelld id set, it should be 211 275 153 189 184 110 124  49 345...\n",
      " [1530  469  774  749 1165 1780 1525  922 1280  509 1689  298  616 1551\n",
      " 1840  327 1865  752 1031]\n"
     ]
    }
   ],
   "source": [
    "#This block will shuffle the id sets of patients in a fix manner, so for every time you run the code, the dataset and trainset are always the same.\n",
    "seed = 2\n",
    "random.seed(seed)\n",
    "if(np.array_equal(Original_Uniq_ID,Uniq_ID) ):\n",
    "    print(\"They are the same. Uniq id hasn't been shuffled, and it will be shuffeld now.\")   \n",
    "    random.shuffle(Uniq_ID)# randomly sorted the patient IDs    \n",
    "else:\n",
    "    print(\"They are not the same. Uniq_id has already been shuffled.\")    \n",
    "print(\"The original uniq id set is:\\n\",Original_Uniq_ID[1:20])\n",
    "print(\"Uniq id:************************************\")\n",
    "print(\"The fixed shuffelld id set, it should be 211 275 153 189 184 110 124  49 345...\\n\",Uniq_ID[1:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fill the missing data with one function\n",
    "# print(filename)\n",
    "# #print(originalData)\n",
    "# if (originalData.isnull().values.any()):\n",
    "#     print('There is data missing in the original data set')\n",
    "# dataByPatient = originalData.groupby('Patient_id') # data grouped by Patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clearAllDatasets():\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    if not X_train.empty: \n",
    "        X_train = X_train[0:0]\n",
    "    if not X_test.empty:\n",
    "        X_test = X_test[0:0]\n",
    "    if not y_train.empty:\n",
    "        y_train = y_train[0:0]\n",
    "    if not y_test.empty:\n",
    "        y_test = y_test[0:0]\n",
    "        \n",
    "def KNN_reset():\n",
    "    #KNN with different K size, \n",
    "    KNN_UtilityScore_mean.clear()\n",
    "    KNN_UtilityScore_std.clear()\n",
    "    KNN_F1Score_mean.clear()\n",
    "    KNN_F1Score_std.clear()\n",
    "    KNN_auroc_mean.clear()\n",
    "    KNN_auprc_mean.clear()\n",
    "    KNN_accuracy_mean.clear()\n",
    "    KNN_accuracy_std.clear()\n",
    "    KNN_positiveprediction_mean.clear()\n",
    "    KNN_baseline_mean.clear()\n",
    "    KNN_total_Time.clear()\n",
    "    \n",
    "def generateTrainDataSet(patienIds):\n",
    "    global X_train, y_train\n",
    "    for i in patienIds:\n",
    "#     print('Patient_id',i,':\\n',dataByPatient.get_group(i),'\\n')\n",
    "        X_train = X_train.append(dataByPatient.get_group(i).loc[:, X_columns])\n",
    "        y_train = y_train.append(dataByPatient.get_group(i).loc[:, y_columns])\n",
    "    return X_train, y_train\n",
    " \n",
    "def generateTestDataSet(patienIds):\n",
    "    global X_test, y_test\n",
    "    for i in patienIds:\n",
    "#     print('Patient_id',i,':\\n',dataByPatient.get_group(i),'\\n')\n",
    "        X_test = X_test.append(dataByPatient.get_group(i).loc[:, X_columns])\n",
    "        y_test = y_test.append(dataByPatient.get_group(i).loc[:, y_columns]) \n",
    "    return X_test, y_test\n",
    "\n",
    "# def CalculateSOFAScore(X_train_impute, X_test_impute):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for K-fold algorithm, Before this step the missing data has been filled, \n",
    "def KFold_patient(model, KforKFold=10,KforKNN=5, fillmethod=\"\"):\n",
    "    start = time.time()# time indicator for how long the Kfold func takes\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    print(\"K Fold of \",KforKFold ,\" folds with KNN =\",KforKNN)\n",
    "    \n",
    "    # initialisation of the array for storing the different intermediate results\n",
    "    accuracy_model = []\n",
    "    F1Score_model = []\n",
    "    baseline_model= []\n",
    "    auroc_model = []\n",
    "    auprc_model = []\n",
    "    physio_accuracy_model = []\n",
    "    f_measure_model = []\n",
    "    utility_score_model = []\n",
    "    mean_train = 0\n",
    "    positivepredictions = []\n",
    "    #The unique id sets have been created and shuffled in a fix manner in the third block, you can just use it here and no more any other manipulation\n",
    "    idSets = np.array_split(Uniq_ID, KforKFold)# divide the ids into K groups\n",
    "    #print(\"Patients number: \", len(Uniq_ID)) #print('idSets arrays',idSets)\n",
    "    #This for loop is for Kfold, calculating the results for K times\n",
    "    for i in range(KforKFold):\n",
    "        start1 = time.time()\n",
    "        clearAllDatasets()\n",
    "#         X_train, X_test, y_train, y_test = flib.clearAllDatasets(X_train, X_test, y_train, y_test) #first clear all the datasets\n",
    "        print(\"for the\",i+1,\"th iteration\",idSets[i])   \n",
    "        t1 = time.time()\n",
    "        X_test,y_test = generateTestDataSet(idSets[i])\n",
    "        print(\"Time for splitting id to test:\", round(time.time()- t1,2))\n",
    "        \n",
    "        t2= time.time()\n",
    "        for j in range(KforKFold):\n",
    "            if j != i:\n",
    "                 X_train, y_train = generateTrainDataSet(idSets[j])\n",
    "        print(\"Time for splitting id to train:\", round(time.time()- t2,2))\n",
    "\n",
    "        #printDataset()\n",
    "        #Now the train and test dataset is generated\n",
    "        #we can begin to train the model wit the training set and evaaulate the performance with the test sett   \n",
    "#         X_train = X_train.drop('time', 1) X_test = X_test.drop('time', 1)\n",
    "        X_train=X_train.astype('float64')\n",
    "        X_test=X_test.astype('float64')    \n",
    "        YTest_copy = y_test  # variable of joining the filled data (X) and Y (Train_output) \n",
    "        patientID_ytest = y_test['Patient_id']\n",
    "        y_train = y_train.drop('Patient_id', 1)\n",
    "        y_test = y_test.drop('Patient_id', 1)      \n",
    "        y_train=y_train.astype('float64')\n",
    "        y_test=y_test.astype('float64')\n",
    "        #print('YTest',YTest_copy.head())\n",
    "        \n",
    "        #fill the missing data\n",
    "        if X_train.isnull().values.any() or X_test.isnull().values.any() :\n",
    "            print(\"X_train or X_test contains NaN values, KNN/mean is performed.\")\n",
    "            #if there is missing value\n",
    "            X_train_impute, X_test_impute, fillmethod = flib.KNNfilling(X_train, X_test, KforKNN, fillmethod)\n",
    "            #X_train_impute, X_test_impute,fillmethod = flib.MeanFilling(X_train,X_test, fillmethod)\n",
    "            #check the missing data   \n",
    "            if np.isnan(X_train_impute).any() or np.isnan(X_test_impute).any() :\n",
    "                print(\"X_train_impute or X_test_impute still contains NaN values\")        \n",
    "            else:\n",
    "                print(\"X_train_impute or X_test_impute have all been filled \")  \n",
    "        else:\n",
    "            print(\"X_train or X_test have all been filled \")\n",
    "            X_train_impute = X_train\n",
    "            X_test_impute = X_test\n",
    "                 \n",
    "        #Scale the data， uncomment this part for logistic regression only, in other case, put them in comment\n",
    "        model_name = type(model).__name__\n",
    "        if (model_name == 'LogisticRegression'):\n",
    "            print(\"scaled!\")\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            scaler.fit(X_train_impute)\n",
    "            X_train_impute = scaler.transform(X_train_impute)\n",
    "            X_test_impute = scaler.transform(X_test_impute)\n",
    "\n",
    "        #fit the model and predict\n",
    "        model.fit(X_train_impute, y_train)\n",
    "        y_predicted = model.predict(X_test_impute)   \n",
    "        y_predicted_probobility = model.predict_proba(X_test_impute) \n",
    "        #transfer the outpu and evalute it\n",
    "        y_labels = y_test.astype(int).to_numpy()\n",
    "        y_predicted = y_predicted.astype(int)\n",
    "        y_predicted_probobility =  y_predicted_probobility[:,1].round(4)\n",
    "        #print(y_labels)      \n",
    "        auroc, auprc, physio_accuracy, f_measure, utility_score = evaluate_performance(y_labels, y_predicted, y_predicted_probobility,patientID_ytest)\n",
    "#         print(\"\\nauroc\",round(auroc,4),\"auprc\",round(auprc,4),\"util_accuracy\",round(accuracy1,4))\n",
    "#         print(\"f_measure\",round(f_measure,4),\"utility_score\",round(utility_score,4))  \n",
    "        auroc_model.append(round(auroc,4))\n",
    "        auprc_model.append(round(auprc,4))\n",
    "        physio_accuracy_model.append(round(physio_accuracy,4))\n",
    "        f_measure_model.append(round(f_measure,4))\n",
    "        utility_score_model.append(round(utility_score,4))\n",
    "        positivepredictions.append(np.sum(y_predicted))\n",
    "\n",
    "        num_rows= X_test_impute.shape[0]\n",
    "        scores = np.zeros(num_rows).astype('float64')# score parameter:output from get_sepsis_score\n",
    "        labels = np.zeros(num_rows).astype('float64')\n",
    "        #WriteToFiles(X_train_impute,YTest_copy,i, fillmethod)\n",
    "        #CalcMean_Std(X_train_impute)\n",
    "        #take down the results\n",
    "        accuracy_model.append((accuracy_score(y_test, y_predicted, normalize=True)*100).round(2))\n",
    "        F1Score_model.append((f1_score(y_test, y_predicted)*100).round(2))\n",
    "        baseline_model.append(round( (1 - float(y_test.mean()) )*100 , 2 ))\n",
    "        print(\"\\ny_test size:\",y_test.shape, '1´s in y_test',y_test.sum())\n",
    "        #baseline_model.append(((1-y_test.mean())*100).round(2))\n",
    "        print(\"The number of 1 (SepsisLabel) in this prediction: \", np.sum(y_predicted))\n",
    "        end1 = time.time()\n",
    "        print(\"Time spent in this KFold iteration\",round(end1-start1,2),\"sec.\\n\")\n",
    "        print(\"******************************************************************\")\n",
    "    print('Accuracy model:', accuracy_model)\n",
    "    print('F1_score model:', F1Score_model)\n",
    "    print('Baseline model:', baseline_model)\n",
    "    \n",
    "    print(\"\\nEvaluation parameters of the utiltiy evaluation function:\")\n",
    "    print('auroc of model:', auroc_model)\n",
    "    print('auprc of model:', auprc_model)\n",
    "    print('Utility accuracy of model:', accuracy_model)\n",
    "    print('utility F1 of model:', f_measure_model)\n",
    "    print('Utility score of model:', utility_score_model)\n",
    "    \n",
    "    KNN_UtilityScore_mean.append(np.mean(utility_score_model))\n",
    "    KNN_UtilityScore_std.append(np.std(utility_score_model))\n",
    "    \n",
    "    KNN_F1Score_mean.append(np.mean(f_measure_model))\n",
    "    KNN_F1Score_std.append(np.std(f_measure_model))\n",
    "    \n",
    "    KNN_auroc_mean.append(np.mean(auroc_model))\n",
    "    KNN_auprc_mean.append(np.mean(auprc_model))\n",
    "    \n",
    "    KNN_accuracy_mean.append(np.mean(physio_accuracy_model))\n",
    "    KNN_accuracy_std.append(np.std(physio_accuracy_model))\n",
    "    \n",
    "    KNN_positiveprediction_mean.append(np.mean(positivepredictions))\n",
    "    KNN_baseline_mean.append(np.mean(baseline_model))\n",
    "    \n",
    "    totalTime=round(time.time()- start,2)\n",
    "    KNN_total_Time.append(totalTime)\n",
    "    \n",
    "    print(\"\\nTotal Time spent in  KFold function\",totalTime,\"sec.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def displayCurrentResult(KforKNNstart,KforKNNend):\n",
    "    print(\"KNN_UtilityScore_mean\",KNN_UtilityScore_mean)\n",
    "    print(\"KNN_UtilityScore_std\",KNN_UtilityScore_std)\n",
    "    print(\"KNN_F1Score_mean\",KNN_F1Score_mean)\n",
    "    print(\"KNN_F1Score_std\",KNN_F1Score_std)\n",
    "    print(\"KNN_auroc_mean\",KNN_auroc_mean)\n",
    "    print(\"KNN_auprc_mean\",KNN_auprc_mean)\n",
    "    print(\"KNN_accuracy_mean\",KNN_accuracy_mean)\n",
    "    print(\"KNN_accuracy_std\",KNN_accuracy_std)\n",
    "    print(\"KNN_positiveprediction_mean\",KNN_positiveprediction_mean)\n",
    "    print(\"KNN_baseline_mean\",KNN_baseline_mean)        \n",
    "    print(len(KNN_accuracy_mean))\n",
    "    print(len(KNN_accuracy_std))\n",
    "    print(len(KNN_F1Score_mean))\n",
    "    print(len(KNN_F1Score_std))\n",
    "    print(len(KNN_positiveprediction_mean))\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_UtilityScore_mean,\"Mean Utility Score vs K\",xlabel='K',ylabel=\"mean Utility Score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_UtilityScore_std,\"std Utility Score vs K\",xlabel='K',ylabel=\"std Utility Score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_F1Score_mean,\"Mean F1 score vs K\",xlabel='K',ylabel=\"Mean F1 score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_F1Score_std,\"Std F1 score vs K\",xlabel='K',ylabel=\"Std F1 score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_accuracy_mean,\"Mean Accuracy vs K\",xlabel='K',ylabel=\"Mean Accuracy\")      \n",
    "def findBestKforKNN(model, KforKFold=10,KforKNNstart=1,KforKNNend=10, stepsize=5):\n",
    "    if(KforKNNend<=1):\n",
    "        print(\"K must be a interger larger than 1\")\n",
    "        return\n",
    "    KNN_reset()\n",
    "    step=stepsize\n",
    "    for i in range(KforKNNstart,KforKNNend+1,step) : \n",
    "        print(\"KNN of K = \",i)    \n",
    "        KFold_patient(model,10,i)\n",
    "    print(\"Now all the training is finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is how to train the model\n",
    "#logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='saga', max_iter=1000,penalty='l1')\n",
    "logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='lbfgs', max_iter=1000)\n",
    "decisionTreeModel = tree.DecisionTreeClassifier(random_state=2)\n",
    "randomForestModel = RandomForestClassifier(random_state=2)\n",
    "XGBoostModel = XGBClassifier(random_state=2)\n",
    "#AdaBoostModel = AdaBoostClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data/raw_data_2000.csv\n",
      "Data isn´t all filled before K-Fold Func\n"
     ]
    }
   ],
   "source": [
    "#fill the missing data with one function\n",
    "print(filename)\n",
    "#print(originalData)\n",
    "if (originalData.isnull().values.any()):\n",
    "    print('Data isn´t all filled before K-Fold Func')\n",
    "    data=originalData\n",
    "#data,fillmethod = flib.linearFillingAll(originalData,1, True)#forwardfilling + fill other missing data with 0\n",
    "dataByPatient = data.groupby('Patient_id') # data grouped by Patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oke\n"
     ]
    }
   ],
   "source": [
    "model_name= decisionTreeModel.__class__.__name__\n",
    "if (model_name == 'DecisionTreeClassifier'):\n",
    "    print(\"oke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(\"Logistic Regression\")\n",
    "#KFold_patient(decisionTreeModel,10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Decision tree\")\n",
    "#KFold_patient(randomForestModel,10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findBestKforKNN(logisticRegressionModel,10,1,10)\n",
    "# findBestKforKNN(XGBoostModel,10,110,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN of K =  1\n",
      "K Fold of  10  folds with KNN = 1\n",
      "for the 1 th iteration [1367 1530  469  774  749 1165 1780 1525  922 1280  509 1689  298  616\n",
      " 1551 1840  327 1865  752 1031 1089  714  291   68 1735  404 1285 1389\n",
      " 1971 1582 1609 1217  499 1120  324  544 1994 1346  501  651 1586  927\n",
      "  778  503 1450 1566 2000 1835 1194  656  387 1009  704 1248 1429 1424\n",
      "  745  266  429  542 1932 1361 1011  839 1220 1554  567 1252  281  196\n",
      " 1413 1386 1416  128  176  875  724  638  479  259  793 1934  817  869\n",
      " 1898  211 1691  306 1235  670  285  853  552 1434 1576  368  162  314\n",
      "  418 1322 1316 1170  696 1921 1976  573 1763 1123 1333  729 1845 1634\n",
      "  267 1863 1095  108  379 1453  312 1229 1830 1886  708 1232 1082 1121\n",
      " 1606 1068  840 1874  375 1883 1838  748 1318  975 1069  871 1732   87\n",
      " 1500 1523 1022 1837  134  182 1514 1065 1967   39 1510 1019 1214  543\n",
      " 1710 1336  821 1038 1908 1399  895  944  398  153 1193  384  599 1086\n",
      "  199  156 1457  245 1795 1478 1144  717 1066  661  352  549  984  340\n",
      "  168 1565 1059   59 1131  891  207 1085  898  422 1782  178 1345 1283\n",
      "  251 1529 1199  365]\n",
      "Time for splitting id to test: 0.73\n",
      "Time for splitting id to train: 27.26\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (8053, 1) 1´s in y_test SepsisLabel    144.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  199\n",
      "Time spent in this KFold iteration 1008.77 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 2 th iteration [ 865 1982  279 1671  780   85  344  837 1436 1136  226  673 1989 1629\n",
      "  926 1430  732 1157  175  463 1181  210 1738 1603 1172  873  483  633\n",
      "  590 1862 1422  630  920 1203  184 1063  827 1139  893  967 1184    3\n",
      "  396 1790  363  163  304 1777  171  776  332   71  812  986 1409 1643\n",
      " 1325   62 1868  710   15  403 1779 1919  834 1635 1698 1993 1027 1204\n",
      " 1896  901  808   16 1535  874 1601   34  755  855  386  715 1133 1118\n",
      " 1726  980 1767 1766 1996  716  706 1304 1661  578  458  136 1084 1648\n",
      " 1099  636 1489 1234  507 1079  947  795  796 1460  667 1498  741  771\n",
      "  887 1511 1153   14 1844 1415 1368  626 1972 1753  366 1265  581  103\n",
      " 1448 1770  685 1480 1309 1659  424  410 1504  224 1889 1797  744 1245\n",
      " 1438   48  734 1692 1975  565 1881 1352  200  260 1173 1748  942 1387\n",
      " 1155  841  884 1138  112 1114  143  328  269 1003 1969  786  886 1926\n",
      "  299  697  798    5 1869  600  760 1590 1195 1137 1196  617 1334 1341\n",
      "  388  486 1823  923 1276 1013  198  772 1621  577 1477  395 1134  265\n",
      "  856  982  132 1080]\n",
      "Time for splitting id to test: 0.64\n",
      "Time for splitting id to train: 15.79\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n"
     ]
    }
   ],
   "source": [
    "findBestKforKNN(decisionTreeModel,10,1,5)\n",
    "os.system('\\a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCurrentResult(1,9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
