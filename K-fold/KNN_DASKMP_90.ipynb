{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask + Multi processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "import dask_ml\n",
    "import joblib\n",
    "import dask\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.csvcsv)\n",
    "import sklearn as sk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing \n",
    "# from sklearn.impute import KNNImputer\n",
    "# #import matplotlib.pyplot as plot\n",
    "# from matplotlib import pyplot\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "# import shutil\n",
    "# import os\n",
    "from our_evaluate_sepsis_score import evaluate_performance_dask\n",
    "import our_functions_library as flib\n",
    "from numba import jit, cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run this once\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:64045</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:64044/status' target='_blank'>http://127.0.0.1:64044/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>16.95 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:64045' processes=4 threads=16, memory=16.95 GB>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.shutdown()\n",
    "#client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Yeah, you may start coding here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: (Delayed('int-f58c8af2-8f3f-4dea-8786-b085e30f750b'), 43)\n",
      "Patient id size: 1000\n",
      "[   1    2    3    4    5    6    7    8    9   10   11   12   13   14\n",
      "   15   16   17   18   19   20   21   22   23   24   25   26   27   28\n",
      "   29   30   31   32   33   34   35   36   37   38   39   40   41   42\n",
      "   43   44   45   46   47   48   49   50   51   52   53   54   55   56\n",
      "   57   58   59   60   61   62   63   64   65   66   67   68   69   70\n",
      "   71   72   73   74   75   76   77   78   79   80   81   82   83   84\n",
      "   85   86   87   88   89   90   91   92   93   94   95   96   97   98\n",
      "   99  100  101  102  103  104  105  106  107  108  109  110  111  112\n",
      "  113  114  115  116  117  118  119  120  121  122  123  124  125  126\n",
      "  127  128  129  130  131  132  133  134  135  136  137  138  139  140\n",
      "  141  142  143  144  145  146  147  148  149  150  151  152  153  154\n",
      "  155  156  157  158  159  160  161  162  163  164  165  166  167  168\n",
      "  169  170  171  172  173  174  175  176  177  178  179  180  181  182\n",
      "  183  184  185  186  187  188  189  190  191  192  193  194  195  196\n",
      "  197  198  199  200  201  202  203  204  205  206  207  208  209  210\n",
      "  211  212  213  214  215  216  217  218  219  220  221  222  223  224\n",
      "  225  226  227  228  229  230  231  232  233  234  235  236  237  238\n",
      "  239  240  241  242  243  244  245  246  247  248  249  250  251  252\n",
      "  253  254  255  256  257  258  259  260  261  262  263  264  265  266\n",
      "  267  268  269  270  271  272  273  274  275  276  277  278  279  280\n",
      "  281  282  283  284  285  286  287  288  289  290  291  292  293  294\n",
      "  295  296  297  298  299  300  301  302  303  304  305  306  307  308\n",
      "  309  310  311  312  313  314  315  316  317  318  319  320  321  322\n",
      "  323  324  325  326  327  328  329  330  331  332  333  334  335  336\n",
      "  337  338  339  340  341  342  343  344  345  346  347  348  349  350\n",
      "  351  352  353  354  355  356  357  358  359  360  361  362  363  364\n",
      "  365  366  367  368  369  370  371  372  373  374  375  376  377  378\n",
      "  379  380  381  382  383  384  385  386  387  388  389  390  391  392\n",
      "  393  394  395  396  397  398  399  400  401  402  403  404  405  406\n",
      "  407  408  409  410  411  412  413  414  415  416  417  418  419  420\n",
      "  421  422  423  424  425  426  427  428  429  430  431  432  433  434\n",
      "  435  436  437  438  439  440  441  442  443  444  445  446  447  448\n",
      "  449  450  451  452  453  454  455  456  457  458  459  460  461  462\n",
      "  463  464  465  466  467  468  469  470  471  472  473  474  475  476\n",
      "  477  478  479  480  481  482  483  484  485  486  487  488  489  490\n",
      "  491  492  493  494  495  496  497  498  499  500  501  502  503  504\n",
      "  505  506  507  508  509  510  511  512  513  514  515  516  517  518\n",
      "  519  520  521  522  523  524  525  526  527  528  529  530  531  532\n",
      "  533  534  535  536  537  538  539  540  541  542  543  544  545  546\n",
      "  547  548  549  550  551  552  553  554  555  556  557  558  559  560\n",
      "  561  562  563  564  565  566  567  568  569  570  571  572  573  574\n",
      "  575  576  577  578  579  580  581  582  583  584  585  586  587  588\n",
      "  589  590  591  592  593  594  595  596  597  598  599  600  601  602\n",
      "  603  604  605  606  607  608  609  610  611  612  613  614  615  616\n",
      "  617  618  619  620  621  622  623  624  625  626  627  628  629  630\n",
      "  631  632  633  634  635  636  637  638  639  640  641  642  643  644\n",
      "  645  646  647  648  649  650  651  652  653  654  655  656  657  658\n",
      "  659  660  661  662  663  664  665  666  667  668  669  670  671  672\n",
      "  673  674  675  676  677  678  679  680  681  682  683  684  685  686\n",
      "  687  688  689  690  691  692  693  694  695  696  697  698  699  700\n",
      "  701  702  703  704  705  706  707  708  709  710  711  712  713  714\n",
      "  715  716  717  718  719  720  721  722  723  724  725  726  727  728\n",
      "  729  730  731  732  733  734  735  736  737  738  739  740  741  742\n",
      "  743  744  745  746  747  748  749  750  751  752  753  754  755  756\n",
      "  757  758  759  760  761  762  763  764  765  766  767  768  769  770\n",
      "  771  772  773  774  775  776  777  778  779  780  781  782  783  784\n",
      "  785  786  787  788  789  790  791  792  793  794  795  796  797  798\n",
      "  799  800  801  802  803  804  805  806  807  808  809  810  811  812\n",
      "  813  814  815  816  817  818  819  820  821  822  823  824  825  826\n",
      "  827  828  829  830  831  832  833  834  835  836  837  838  839  840\n",
      "  841  842  843  844  845  846  847  848  849  850  851  852  853  854\n",
      "  855  856  857  858  859  860  861  862  863  864  865  866  867  868\n",
      "  869  870  871  872  873  874  875  876  877  878  879  880  881  882\n",
      "  883  884  885  886  887  888  889  890  891  892  893  894  895  896\n",
      "  897  898  899  900  901  902  903  904  905  906  907  908  909  910\n",
      "  911  912  913  914  915  916  917  918  919  920  921  922  923  924\n",
      "  925  926  927  928  929  930  931  932  933  934  935  936  937  938\n",
      "  939  940  941  942  943  944  945  946  947  948  949  950  951  952\n",
      "  953  954  955  956  957  958  959  960  961  962  963  964  965  966\n",
      "  967  968  969  970  971  972  973  974  975  976  977  978  979  980\n",
      "  981  982  983  984  985  986  987  988  989  990  991  992  993  994\n",
      "  995  996  997  998  999 1000]\n"
     ]
    }
   ],
   "source": [
    "# dataType={'Age': 'int', 'Gender': bool, 'Patient_id': int, 'time': 'int8', 'SepsisLabel':'float16'}\n",
    "filename = '../../raw_data/raw_data_1000.csv' # use raw dataset\n",
    "originalData = dd.read_csv(filename,dtype={'Gender':bool,'SepsisLabel':bool}) # read csv data into Dask DataFrame\n",
    "Uniq_ID= np.unique(originalData['Patient_id'])\n",
    "print(\"Data size:\",originalData.shape)\n",
    "print('Patient id size:',len(Uniq_ID))\n",
    "print(Uniq_ID)\n",
    "\n",
    "X_full_columns = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2','BaseExcess', 'HCO3', 'FiO2', 'pH', \n",
    "             'PaCO2', 'SaO2', 'AST', 'BUN','Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
    "             'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium','Bilirubin_total', 'TroponinI', 'Hct', \n",
    "             'Hgb', 'PTT', 'WBC','Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2','HospAdmTime',\n",
    "             'ICULOS', 'Patient_id', 'time']\n",
    "y_full_columns = ['Patient_id', 'SepsisLabel']\n",
    "\n",
    "# To test if these 3 columns is useful\n",
    "# originalData = originalData.drop(['Unit1', 'Unit2', 'EtCO2'], axis=1)\n",
    "# X_columns.remove('Unit1')\n",
    "# X_columns.remove( 'Unit2')\n",
    "# X_columns.remove( 'EtCO2')\n",
    "\n",
    "# Initialize the empty array X_train, X_test, y_train, y_test\n",
    "# X_train = dd.from_pandas(pd.DataFrame(columns = X_columns),npartitions=2)\n",
    "# X_test = dd.from_pandas(pd.DataFrame(columns = X_columns),npartitions=2)\n",
    "# y_train = dd.from_pandas(pd.DataFrame(columns = y_columns),npartitions=2)\n",
    "# y_test = dd.from_pandas(pd.DataFrame(columns = y_columns),npartitions=2)\n",
    "\n",
    "# Below are the lists for KNN results of different K value\n",
    "KNN_UtilityScore_mean = []\n",
    "KNN_UtilityScore_std = []\n",
    "KNN_F1Score_mean = []\n",
    "KNN_F1Score_std = []\n",
    "KNN_auroc_mean = []\n",
    "KNN_auprc_mean = []\n",
    "KNN_accuracy_mean = []\n",
    "KNN_accuracy_std = []\n",
    "KNN_positiveprediction_mean = []\n",
    "KNN_baseline_mean = [ ]\n",
    "KNN_total_Time= [ ]\n",
    "fillmethod =\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set size: (38890, 43)\n",
      "5064968\n"
     ]
    }
   ],
   "source": [
    "print(\"Data set size:\",originalData.compute().shape)\n",
    "print(originalData.memory_usage(deep=True).sum().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'Glucose', 'Age', 'Gender', 'Unit1', 'Unit2', 'HospAdmTime', 'ICULOS', 'SepsisLabel', 'Patient_id', 'time']\n",
      "['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'Glucose', 'Age', 'Gender', 'Unit1', 'Unit2', 'HospAdmTime', 'ICULOS', 'Patient_id', 'time']\n"
     ]
    }
   ],
   "source": [
    "missing = originalData.isna().sum()/len(originalData)*100\n",
    "almostMissingColumns = list(missing[missing>90].index)\n",
    "# print(almostMissingColumns)\n",
    "leftAllColumns = list(originalData.columns).copy()\n",
    "# print(leftAllColumns)\n",
    "leftAllColumns =  [i for i in leftAllColumns if i not in almostMissingColumns]\n",
    "# print(leftAllColumns)\n",
    "trainColumns = leftAllColumns.copy()\n",
    "# trainColumns.remove('time')\n",
    "trainColumns.remove('SepsisLabel')\n",
    "# print(missing.compute())\n",
    "print(leftAllColumns)\n",
    "print(trainColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      HR  O2Sat   Temp    SBP     MAP  DBP  Resp  Glucose    Age  Gender  \\\n",
      "0   97.0   95.0  36.11   98.0  75.330  0.0  19.0    193.0  83.14   False   \n",
      "1   97.0   95.0  36.11   98.0  75.330  0.0  19.0    193.0  83.14   False   \n",
      "2   89.0   99.0  36.11  122.0  86.000  0.0  22.0    193.0  83.14   False   \n",
      "3   90.0   95.0  36.11  122.0  88.665  0.0  30.0    193.0  83.14   False   \n",
      "4  103.0   88.5  36.11  122.0  91.330  0.0  24.5    193.0  83.14   False   \n",
      "\n",
      "   Unit1  Unit2  HospAdmTime  ICULOS  SepsisLabel  Patient_id  time  \n",
      "0    0.0    0.0        -0.03       1        False           1     0  \n",
      "1    0.0    0.0        -0.03       2        False           1     1  \n",
      "2    0.0    0.0        -0.03       3        False           1     2  \n",
      "3    0.0    0.0        -0.03       4        False           1     3  \n",
      "4    0.0    0.0        -0.03       5        False           1     4  \n"
     ]
    }
   ],
   "source": [
    "originalData = originalData[leftAllColumns]\n",
    "print(originalData.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filling using Forward filling\n",
      "The filling choice is of number: 2\n",
      "HR             0.0\n",
      "O2Sat          0.0\n",
      "Temp           0.0\n",
      "SBP            0.0\n",
      "MAP            0.0\n",
      "DBP            0.0\n",
      "Resp           0.0\n",
      "Glucose        0.0\n",
      "Age            0.0\n",
      "Gender         0.0\n",
      "Unit1          0.0\n",
      "Unit2          0.0\n",
      "HospAdmTime    0.0\n",
      "ICULOS         0.0\n",
      "SepsisLabel    0.0\n",
      "Patient_id     0.0\n",
      "time           0.0\n",
      "dtype: float64\n",
      "fillingChoice =2\n",
      "total time: 15.25 sec\n"
     ]
    }
   ],
   "source": [
    "#data, fillmethod = flib.linearFillingAll(originalData)#\n",
    "#data = flib.linearFillingAll(originalData,1)#fill other missing data with 0\n",
    "#data = flib.linearFillingAll(originalData,2,)#fill other missing data with overall average value\n",
    "#data = flib.linearFillingAll(originalData,0,True)#forwardfilling\n",
    "#data = flib.linearFillingAll(originalData,1, True)#forwardfilling + fill other missing data with 0\n",
    "originalData,fillingmethod = flib.linearFillingAll(originalData.compute(),2,True)#forwardfilling + fill other missing data with overall average value\n",
    "#oridata after linearly imputation is filled, so oridata needs to be generated again\n",
    "#print(originalData)\n",
    "if (originalData.isnull().values.any()):\n",
    "    print('Data isn´t all filled before K-Fold Func')\n",
    "originalData = dd.from_pandas(originalData,npartitions = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HR</th>\n",
       "      <th>O2Sat</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SBP</th>\n",
       "      <th>MAP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>Resp</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Unit1</th>\n",
       "      <th>Unit2</th>\n",
       "      <th>HospAdmTime</th>\n",
       "      <th>ICULOS</th>\n",
       "      <th>SepsisLabel</th>\n",
       "      <th>Patient_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>36.11</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>97.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>36.11</td>\n",
       "      <td>98.0</td>\n",
       "      <td>75.330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.11</td>\n",
       "      <td>122.0</td>\n",
       "      <td>86.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>36.11</td>\n",
       "      <td>122.0</td>\n",
       "      <td>88.665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>36.11</td>\n",
       "      <td>122.0</td>\n",
       "      <td>91.330</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>193.0</td>\n",
       "      <td>83.14</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HR  O2Sat   Temp    SBP     MAP  DBP  Resp  Glucose    Age  Gender  \\\n",
       "0   97.0   95.0  36.11   98.0  75.330  0.0  19.0    193.0  83.14   False   \n",
       "1   97.0   95.0  36.11   98.0  75.330  0.0  19.0    193.0  83.14   False   \n",
       "2   89.0   99.0  36.11  122.0  86.000  0.0  22.0    193.0  83.14   False   \n",
       "3   90.0   95.0  36.11  122.0  88.665  0.0  30.0    193.0  83.14   False   \n",
       "4  103.0   88.5  36.11  122.0  91.330  0.0  24.5    193.0  83.14   False   \n",
       "\n",
       "   Unit1  Unit2  HospAdmTime  ICULOS  SepsisLabel  Patient_id  time  \n",
       "0    0.0    0.0        -0.03       1        False           1     0  \n",
       "1    0.0    0.0        -0.03       2        False           1     1  \n",
       "2    0.0    0.0        -0.03       3        False           1     2  \n",
       "3    0.0    0.0        -0.03       4        False           1     3  \n",
       "4    0.0    0.0        -0.03       5        False           1     4  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They are not the same. Uniq_id has already been shuffled.\n",
      "The fixed shuffelld id set, it should be 211 275 153...\n",
      " [291 215 113 545 697 542 794 673 660 340 299 646 822 497  93 290 207 212\n",
      " 633 219]\n"
     ]
    }
   ],
   "source": [
    "#This block will shuffle the id sets of patients in a fix manner, so for every time you run the code, the dataset and trainset are always the same.\n",
    "seed = 2\n",
    "random.seed(seed)\n",
    "if(np.array_equal(range(1,21),Uniq_ID[:20]) ):\n",
    "    print(\"The original uniq id set is:\\n\",Uniq_ID[0:20])\n",
    "    print(\"The first 20 patient ids are the same. Uniq id hasn't been shuffled, and it will be shuffeld now.\")   \n",
    "    random.shuffle(Uniq_ID)# randomly sorted the patient IDs \n",
    "#     Uniq_ID = da.from_array(Uniq_ID)\n",
    "else:\n",
    "    print(\"They are not the same. Uniq_id has already been shuffled.\")    \n",
    "\n",
    "print(\"The fixed shuffelld id set, it should be 211 275 153...\\n\",Uniq_ID[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_reset():\n",
    "    KNN_UtilityScore_mean.clear()\n",
    "    KNN_UtilityScore_std.clear()\n",
    "    KNN_F1Score_mean.clear()\n",
    "    KNN_F1Score_std.clear()\n",
    "    KNN_auroc_mean.clear()\n",
    "    KNN_auprc_mean.clear()\n",
    "    KNN_accuracy_mean.clear()\n",
    "    KNN_accuracy_std.clear()\n",
    "    KNN_positiveprediction_mean.clear()\n",
    "    KNN_baseline_mean.clear()\n",
    "    KNN_total_Time.clear()\n",
    "\n",
    "def generateTrainDataSet(originalData,test_patienIds, X_columns = X_full_columns, y_columns = y_full_columns):\n",
    "    train_data= originalData[~(originalData.Patient_id.isin(test_patienIds))]\n",
    "    X_train = train_data[X_columns]\n",
    "    y_train = train_data[y_columns] \n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "#Function to generate the test dataset\n",
    "def generateTestDataSet(originalData,patienIds,X_columns = X_full_columns, y_columns = y_full_columns):\n",
    "    print(\"test_patienIds: \\n\", patienIds)\n",
    "    test_data = originalData[originalData['Patient_id'].isin(patienIds)]\n",
    "    X_test = test_data[X_columns]\n",
    "    y_test = test_data[y_columns]\n",
    "    return X_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for 1 fold in Kfold\n",
    "def OneFold_patient_MP(i,model,KforKNN,idSets,fillmethod = \"\"): \n",
    "    start1 = time.time()\n",
    "    print(\"for the\",i+1,\"th iteration: \")\n",
    "    X_test,y_test = generateTestDataSet(originalData,idSets[i],X_columns = trainColumns)\n",
    "    print(\"Time for splitting id to test dataset:\", round(time.time()- start1,3))\n",
    "    t1 = time.time()\n",
    "    X_train, y_train = generateTrainDataSet(originalData,idSets[i],X_columns = trainColumns)\n",
    "    print(\"Time for splitting id to train dataset:\", round(time.time()- t1,3))\n",
    "\n",
    "    #Now the train and test dataset is generated \n",
    "    patientID_ytest = y_test['Patient_id']\n",
    "    y_test = y_test.drop('Patient_id', 1) \n",
    "    y_train = y_train.drop('Patient_id', 1)\n",
    "    X_train=X_train.astype('float32')\n",
    "    X_test=X_test.astype('float32') \n",
    "    y_train=y_train.astype('bool')\n",
    "    y_test=y_test.astype('bool')\n",
    "    print(X_train)\n",
    "    \n",
    "    #fill the missing data\n",
    "    if X_train.isnull().values.any() or X_test.isnull().values.any() :\n",
    "        t1= time.time()\n",
    "        print(\"X_train or X_test contains NaN values, KNN is performed.\")\n",
    "#         X_train, X_test,fillmethod = flib.MeanFilling(X_train,X_test, fillmethod)  \n",
    "        X_train, X_test, fillmethod = flib.KNNfilling(X_train, X_test, KforKNN)\n",
    "        print(\"The type of X_train after KNN filling is\",type(X_train))\n",
    "        print(\"Time for NaN values filling: \", round(time.time()- t1,2) )\n",
    "        X_train = dd.from_array(X_train)\n",
    "        X_test = dd.from_array(X_test)\n",
    "        if  X_train.isnull().values.any() or X_test.isnull().values.any() :\n",
    "            print(\"X_train or X_test still contains NaN values after filling\")          \n",
    "    print(\"The type of X_train after KNN filling is\",type(X_train))\n",
    "    \n",
    "    \n",
    "    if ( type(model).__name__ == 'LogisticRegression'):  #Scale the data for logistic regression\n",
    "        t1 = time.time()\n",
    "        scaler = dask_ml.preprocessing.StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        print(\"Standard Scaling time: \", round(time.time()- t1,2) )\n",
    "\n",
    "               \n",
    "    #fit the model and predict\n",
    "    with joblib.parallel_backend(\"dask\",scatter=[X_train, y_train]):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predicted = model.predict(X_test).astype(bool)   \n",
    "        y_predicted_probobility = model.predict_proba(X_test).astype('float32') \n",
    "    y_labels = dd.from_pandas(y_test['SepsisLabel'].compute().reset_index(drop=True),npartitions = 2)\n",
    "    \n",
    "#     if(i == 1):\n",
    "#             # create excel writer object\n",
    "#         writer = pd.ExcelWriter('X_train_90dropped_linearf.xlsx')\n",
    "#         # write dataframe to excel\n",
    "#         X_train.compute().to_excel(writer)\n",
    "#         # save the excel\n",
    "#         writer.save()\n",
    "        \n",
    "    del X_train, X_test, y_train\n",
    "\n",
    "    print(\"columns of y_predicted_probobility is: \",len(y_predicted_probobility[0]))\n",
    "    if(len(y_predicted_probobility[0]) ==2 ):\n",
    "        y_predicted_probobility =  y_predicted_probobility[:,1].round(4)\n",
    "    elif(len(y_predicted_probobility[0]) == 1):     \n",
    "        y_predicted_probobility =  y_predicted_probobility.round(4)\n",
    "    \n",
    "    auroc, auprc, physio_accuracy, f_measure, utility_score = evaluate_performance_dask(y_labels.compute(), y_predicted, y_predicted_probobility,patientID_ytest.compute(),idSets[i]) \n",
    "    del y_labels, y_predicted_probobility    \n",
    "    result = { \"auroc\": round(auroc,4), \"auprc\": round(auprc,4), \"f_measure\": round(f_measure,4),\n",
    "                \"physio_accuracy\": round(physio_accuracy,4),\"utility_score\": round(utility_score,4), \n",
    "                \"positiveprediction\": np.sum(y_predicted), \n",
    "            \"baseline\": round( (1 - round(y_test.mean().compute().loc['SepsisLabel'],2) )*100 , 2 )}\n",
    "    print(\"\\ny_test size:\",y_test.shape, '1´s in y_test',y_test.sum())\n",
    "    del  y_test\n",
    "    print(\"Time spent in \",i,\"th Fold iteration\",round(time.time()-start1,2),\"sec.\\n\")\n",
    "    print(\"******************************************************************\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for K-fold algorithm using multi processes\n",
    "def KFold_patient_DASKMP(model, KforKFold=10,KforKNN=5, fillmethod=\"\"):\n",
    "    start = time.time()# time indicator for how long the Kfold func takes  \n",
    "    print(\"Datasize\",len(Uniq_ID) ,\"with K Fold of \",KforKFold ,\" folds filling by KNN =\",KforKNN)\n",
    "    # initialisation of the array for storing the different intermediate results\n",
    "    auroc_model = []\n",
    "    auprc_model = []\n",
    "    f_measure_model = []\n",
    "    physio_accuracy_model = []\n",
    "    utility_score_model = []\n",
    "    positivepredictions = []\n",
    "    baseline_model= []\n",
    "    #The unique id sets have been created and shuffled in a fix manner in the third block, you can just use it here and no more any other manipulation\n",
    "    idSets = np.array_split(Uniq_ID, KforKFold)# divide the ids into K groups\n",
    "\n",
    "    flib.WritePatientIdsToFile(idSets, KforKFold)\n",
    "\n",
    "#     OneFold_patient_MP(1, model, KforKNN,idSets)\n",
    "    \n",
    "    futures = []\n",
    "    for i in range(0,KforKFold):\n",
    "        print(i)\n",
    "        f = client.submit(OneFold_patient_MP,i, model, KforKNN,idSets,fillmethod)\n",
    "        futures.append(f)\n",
    "\n",
    "    for f in futures:\n",
    "        result = f.result()\n",
    "        auroc_model.append(result[\"auroc\"])\n",
    "        auprc_model.append(result[\"auprc\"])\n",
    "        f_measure_model.append(result[\"f_measure\"])\n",
    "        physio_accuracy_model.append(result[\"physio_accuracy\"])  \n",
    "        utility_score_model.append(result[\"utility_score\"])\n",
    "        positivepredictions.append(result[\"positiveprediction\"])\n",
    "        baseline_model.append(result[\"baseline\"])        \n",
    "    print(\"\\nEvaluation parameters of the utiltiy evaluation function:\")\n",
    "    print('Utility score of model:', utility_score_model)\n",
    "    print('utility F1 of model:', f_measure_model)\n",
    "    print('Utility accuracy of model:', physio_accuracy_model) \n",
    "    print('auroc of model:', auroc_model)\n",
    "    print('auprc of model:', auprc_model)\n",
    "    print(\"Positive Prediction: \", positivepredictions)\n",
    "    print('Baseline model:', baseline_model)  \n",
    "    KNN_auroc_mean.append(np.mean(auroc_model))\n",
    "    KNN_auprc_mean.append(np.mean(auprc_model))\n",
    "    KNN_F1Score_mean.append(np.mean(f_measure_model))\n",
    "    KNN_F1Score_std.append(np.std(f_measure_model))\n",
    "    KNN_accuracy_mean.append(np.mean(physio_accuracy_model))\n",
    "    KNN_accuracy_std.append(np.std(physio_accuracy_model))\n",
    "    KNN_UtilityScore_mean.append(np.mean(utility_score_model))\n",
    "    KNN_UtilityScore_std.append(np.std(utility_score_model))\n",
    "    KNN_positiveprediction_mean.append(np.mean(positivepredictions))\n",
    "    KNN_baseline_mean.append(np.mean(baseline_model))\n",
    "    \n",
    "    totalTime=round(time.time()- start,2)\n",
    "    KNN_total_Time.append(totalTime)\n",
    "    print(\"\\nTotal Time spent in  KFold function\",totalTime,\"sec.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='saga', max_iter=1000,penalty='l1')\n",
    "logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='lbfgs', max_iter=1000)\n",
    "decisionTreeModel = tree.DecisionTreeClassifier(random_state=2)\n",
    "randomForestModel = RandomForestClassifier(random_state=2)\n",
    "XGBoostModel = XGBClassifier(random_state=2, n_jobs=4)\n",
    "#AdaBoostModel = AdaBoostClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasize 1000 with K Fold of  10  folds filling by KNN = 25\n",
      "Time for writing id to file: 0.0\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "\n",
      "Evaluation parameters of the utiltiy evaluation function:\n",
      "Utility score of model: [0.1098, 0.1429, 0.0748, 0.2532, 0.1712, -0.021, 0.2447, 0.2223, 0.1197, 0.2452]\n",
      "utility F1 of model: [0.0787, 0.1284, 0.0979, 0.297, 0.1121, 0.0168, 0.1394, 0.1467, 0.093, 0.2277]\n",
      "Utility accuracy of model: [0.9359, 0.9563, 0.9627, 0.9798, 0.9514, 0.9691, 0.9355, 0.9445, 0.8979, 0.9598]\n",
      "auroc of model: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "auprc of model: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Positive Prediction:  [207, 136, 77, 44, 183, 63, 228, 193, 365, 118]\n",
      "Baseline model: [99.0, 98.0, 98.0, 98.0, 99.0, 99.0, 98.0, 98.0, 97.0, 98.0]\n",
      "\n",
      "Total Time spent in  KFold function 5.28 sec.\n",
      "\n",
      "Wall time: 5.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "KFold_patient_DASKMP(decisionTreeModel,10,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-29-5169cefc923b>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0my_labels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'y_labels' is not defined"
     ]
    }
   ],
   "source": [
    "y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"X_train size is: \",X_train.size * X_train.itemsize)\n",
    "# print(\"X_test size is: \",X_test.size * X_test.itemsize)\n",
    "# print(\"X_train size is: \",X_train.memory_usage(deep=True).sum().compute())\n",
    "# print(\"X_test size is: \",X_test.memory_usage(deep=True).sum().compute())\n",
    "# print(\"y_train size is: \",y_train.memory_usage(deep=True).sum().compute())\n",
    "# print(\"y_test size is: \",y_test.memory_usage(deep=True).sum().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Print_DATA():\n",
    "    print(\"Numbers of K:\",len(KNN_accuracy_mean))\n",
    "    print(\"KNN_UtilityScore_mean\", KNN_UtilityScore_mean)\n",
    "    print(\"KNN_UtilityScore_std\", KNN_UtilityScore_std)\n",
    "    print(\"KNN_F1Score_mean\", KNN_F1Score_mean)\n",
    "    print(\"KNN_F1Score_std\", KNN_F1Score_std)\n",
    "    print(\"KNN_auroc_mean\", KNN_auroc_mean)\n",
    "    print(\"KNN_auprc_mean\", KNN_auprc_mean)\n",
    "    print(\"KNN_accuracy_mean\", KNN_accuracy_mean)\n",
    "    print(\"KNN_accuracy_std\", KNN_accuracy_std)\n",
    "    print(\"KNN_positiveprediction_mean\", KNN_positiveprediction_mean)\n",
    "    print(\"KNN_baseline_mean\", KNN_baseline_mean)\n",
    "    print(\"KNN_total_time\", KNN_total_Time)      \n",
    "\n",
    "def findBestKforKNN(model, KforKFold=10,KforKNNstart=1,KforKNNend=10, stepsize=5):\n",
    "    if(KforKNNend<=1):\n",
    "        print(\"K must be a interger larger than 1\")\n",
    "        return\n",
    "    KNN_reset()\n",
    "    step=stepsize\n",
    "    for i in range(KforKNNstart,KforKNNend+1,step) : \n",
    "        print(\"KNN of K = \",i)    \n",
    "        KFold_patient(model,10,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Print_DATA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}