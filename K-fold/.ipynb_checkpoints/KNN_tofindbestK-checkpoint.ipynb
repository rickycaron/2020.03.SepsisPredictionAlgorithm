{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code to find the most suitable K value for the KNN filling algorithm\n",
    "Since Logistic regression performs and worst among all algorithm, we don't use it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.csvcsv)\n",
    "import sklearn\n",
    "# Cross Validation Classification Accuracy\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing \n",
    "from sklearn.impute import KNNImputer\n",
    "#import matplotlib.pyplot as plot\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn import tree\n",
    "import statistics\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# plotting errorbar graph for visual representation of the performance of the classifiers\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import Affine2D\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "import shutil\n",
    "import os\n",
    "import ipynb.fs.full.our_functions_library as flib\n",
    "from our_evaluate_sepsis_score import evaluate_performance\n",
    "#from our_functions_library import *\n",
    "# import numba\n",
    "# from numba import jit, njit, cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: (38890, 43)\n",
      "Patient id size: 1000\n",
      "[   1    2    3    4    5    6    7    8    9   10   11   12   13   14\n",
      "   15   16   17   18   19   20   21   22   23   24   25   26   27   28\n",
      "   29   30   31   32   33   34   35   36   37   38   39   40   41   42\n",
      "   43   44   45   46   47   48   49   50   51   52   53   54   55   56\n",
      "   57   58   59   60   61   62   63   64   65   66   67   68   69   70\n",
      "   71   72   73   74   75   76   77   78   79   80   81   82   83   84\n",
      "   85   86   87   88   89   90   91   92   93   94   95   96   97   98\n",
      "   99  100  101  102  103  104  105  106  107  108  109  110  111  112\n",
      "  113  114  115  116  117  118  119  120  121  122  123  124  125  126\n",
      "  127  128  129  130  131  132  133  134  135  136  137  138  139  140\n",
      "  141  142  143  144  145  146  147  148  149  150  151  152  153  154\n",
      "  155  156  157  158  159  160  161  162  163  164  165  166  167  168\n",
      "  169  170  171  172  173  174  175  176  177  178  179  180  181  182\n",
      "  183  184  185  186  187  188  189  190  191  192  193  194  195  196\n",
      "  197  198  199  200  201  202  203  204  205  206  207  208  209  210\n",
      "  211  212  213  214  215  216  217  218  219  220  221  222  223  224\n",
      "  225  226  227  228  229  230  231  232  233  234  235  236  237  238\n",
      "  239  240  241  242  243  244  245  246  247  248  249  250  251  252\n",
      "  253  254  255  256  257  258  259  260  261  262  263  264  265  266\n",
      "  267  268  269  270  271  272  273  274  275  276  277  278  279  280\n",
      "  281  282  283  284  285  286  287  288  289  290  291  292  293  294\n",
      "  295  296  297  298  299  300  301  302  303  304  305  306  307  308\n",
      "  309  310  311  312  313  314  315  316  317  318  319  320  321  322\n",
      "  323  324  325  326  327  328  329  330  331  332  333  334  335  336\n",
      "  337  338  339  340  341  342  343  344  345  346  347  348  349  350\n",
      "  351  352  353  354  355  356  357  358  359  360  361  362  363  364\n",
      "  365  366  367  368  369  370  371  372  373  374  375  376  377  378\n",
      "  379  380  381  382  383  384  385  386  387  388  389  390  391  392\n",
      "  393  394  395  396  397  398  399  400  401  402  403  404  405  406\n",
      "  407  408  409  410  411  412  413  414  415  416  417  418  419  420\n",
      "  421  422  423  424  425  426  427  428  429  430  431  432  433  434\n",
      "  435  436  437  438  439  440  441  442  443  444  445  446  447  448\n",
      "  449  450  451  452  453  454  455  456  457  458  459  460  461  462\n",
      "  463  464  465  466  467  468  469  470  471  472  473  474  475  476\n",
      "  477  478  479  480  481  482  483  484  485  486  487  488  489  490\n",
      "  491  492  493  494  495  496  497  498  499  500  501  502  503  504\n",
      "  505  506  507  508  509  510  511  512  513  514  515  516  517  518\n",
      "  519  520  521  522  523  524  525  526  527  528  529  530  531  532\n",
      "  533  534  535  536  537  538  539  540  541  542  543  544  545  546\n",
      "  547  548  549  550  551  552  553  554  555  556  557  558  559  560\n",
      "  561  562  563  564  565  566  567  568  569  570  571  572  573  574\n",
      "  575  576  577  578  579  580  581  582  583  584  585  586  587  588\n",
      "  589  590  591  592  593  594  595  596  597  598  599  600  601  602\n",
      "  603  604  605  606  607  608  609  610  611  612  613  614  615  616\n",
      "  617  618  619  620  621  622  623  624  625  626  627  628  629  630\n",
      "  631  632  633  634  635  636  637  638  639  640  641  642  643  644\n",
      "  645  646  647  648  649  650  651  652  653  654  655  656  657  658\n",
      "  659  660  661  662  663  664  665  666  667  668  669  670  671  672\n",
      "  673  674  675  676  677  678  679  680  681  682  683  684  685  686\n",
      "  687  688  689  690  691  692  693  694  695  696  697  698  699  700\n",
      "  701  702  703  704  705  706  707  708  709  710  711  712  713  714\n",
      "  715  716  717  718  719  720  721  722  723  724  725  726  727  728\n",
      "  729  730  731  732  733  734  735  736  737  738  739  740  741  742\n",
      "  743  744  745  746  747  748  749  750  751  752  753  754  755  756\n",
      "  757  758  759  760  761  762  763  764  765  766  767  768  769  770\n",
      "  771  772  773  774  775  776  777  778  779  780  781  782  783  784\n",
      "  785  786  787  788  789  790  791  792  793  794  795  796  797  798\n",
      "  799  800  801  802  803  804  805  806  807  808  809  810  811  812\n",
      "  813  814  815  816  817  818  819  820  821  822  823  824  825  826\n",
      "  827  828  829  830  831  832  833  834  835  836  837  838  839  840\n",
      "  841  842  843  844  845  846  847  848  849  850  851  852  853  854\n",
      "  855  856  857  858  859  860  861  862  863  864  865  866  867  868\n",
      "  869  870  871  872  873  874  875  876  877  878  879  880  881  882\n",
      "  883  884  885  886  887  888  889  890  891  892  893  894  895  896\n",
      "  897  898  899  900  901  902  903  904  905  906  907  908  909  910\n",
      "  911  912  913  914  915  916  917  918  919  920  921  922  923  924\n",
      "  925  926  927  928  929  930  931  932  933  934  935  936  937  938\n",
      "  939  940  941  942  943  944  945  946  947  948  949  950  951  952\n",
      "  953  954  955  956  957  958  959  960  961  962  963  964  965  966\n",
      "  967  968  969  970  971  972  973  974  975  976  977  978  979  980\n",
      "  981  982  983  984  985  986  987  988  989  990  991  992  993  994\n",
      "  995  996  997  998  999 1000]\n",
      "length of an array 20\n",
      "range(1, 21)\n"
     ]
    }
   ],
   "source": [
    "# Global initialization, get all the data from file and generate all the needed variable\n",
    "filename = '../../raw_data/raw_data_1000.csv' # use raw dataset\n",
    "originalData = pd.read_csv(filename) # read csv data into DataFrame var raw\n",
    "print(\"Data size:\",originalData.shape)\n",
    "Uniq_ID= np.unique(originalData['Patient_id']) \n",
    "print('Patient id size:',len(Uniq_ID))\n",
    "print(Uniq_ID)\n",
    "Original_Uniq_ID_head = range(1,21)\n",
    "print(\"length of an array\",len(Original_Uniq_ID_head))\n",
    "print(Original_Uniq_ID_head)\n",
    "\n",
    "X_columns = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2','BaseExcess', 'HCO3', 'FiO2', 'pH', \n",
    "             'PaCO2', 'SaO2', 'AST', 'BUN','Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
    "             'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium','Bilirubin_total', 'TroponinI', 'Hct', \n",
    "             'Hgb', 'PTT', 'WBC','Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2','HospAdmTime',\n",
    "             'ICULOS', 'Patient_id', 'time']\n",
    "y_columns = ['Patient_id', 'SepsisLabel']\n",
    "\n",
    "# To test if these 3 columns is useful\n",
    "# originalData = originalData.drop(['Unit1', 'Unit2', 'EtCO2'], axis=1)\n",
    "# X_columns.remove('Unit1')\n",
    "# X_columns.remove( 'Unit2')\n",
    "# X_columns.remove( 'EtCO2')\n",
    "\n",
    "# Initialize the empty array X_train, X_test, y_train, y_test\n",
    "X_train = pd.DataFrame(columns = X_columns)\n",
    "X_test = pd.DataFrame(columns = X_columns)\n",
    "y_train = pd.DataFrame(columns = y_columns)\n",
    "y_test = pd.DataFrame(columns = y_columns)\n",
    "\n",
    "# Below are the lists for KNN results of different K value\n",
    "KNN_UtilityScore_mean = []\n",
    "KNN_UtilityScore_std = []\n",
    "KNN_F1Score_mean = []\n",
    "KNN_F1Score_std = []\n",
    "KNN_auroc_mean = []\n",
    "KNN_auprc_mean = []\n",
    "KNN_accuracy_mean = []\n",
    "KNN_accuracy_std = []\n",
    "KNN_positiveprediction_mean = []\n",
    "KNN_baseline_mean = [ ]\n",
    "KNN_total_Time= [ ]\n",
    "fillmethod =\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 20 patient ids are the same. Uniq id hasn't been shuffled, and it will be shuffeld now.\n",
      "The original uniq id set is:\n",
      " [291 215 113 545 697 542 794 673 660 340 299 646 822 497  93 290 207 212\n",
      " 633 219]\n",
      "The fixed shuffelld id set, it should be 211 275 153 189 184 110 124  49...\n",
      " [291 215 113 545 697 542 794 673 660 340 299 646 822 497  93 290 207 212\n",
      " 633 219]\n"
     ]
    }
   ],
   "source": [
    "#This block will shuffle the id sets of patients in a fix manner, so for every time you run the code, the dataset and trainset are always the same.\n",
    "seed = 2\n",
    "random.seed(seed)\n",
    "if(np.array_equal(Original_Uniq_ID_head,Uniq_ID[:20]) ):\n",
    "    print(\"The first 20 patient ids are the same. Uniq id hasn't been shuffled, and it will be shuffeld now.\")   \n",
    "    random.shuffle(Uniq_ID)# randomly sorted the patient IDs    \n",
    "else:\n",
    "    print(\"They are not the same. Uniq_id has already been shuffled.\")    \n",
    "print(\"The original uniq id set is:\\n\",Uniq_ID[0:20])\n",
    "print(\"The fixed shuffelld id set, it should be 211 275 153 189 184 110 124  49...\\n\",Uniq_ID[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_reset():\n",
    "    #KNN with different K size, \n",
    "    KNN_UtilityScore_mean.clear()\n",
    "    KNN_UtilityScore_std.clear()\n",
    "    KNN_F1Score_mean.clear()\n",
    "    KNN_F1Score_std.clear()\n",
    "    KNN_auroc_mean.clear()\n",
    "    KNN_auprc_mean.clear()\n",
    "    KNN_accuracy_mean.clear()\n",
    "    KNN_accuracy_std.clear()\n",
    "    KNN_positiveprediction_mean.clear()\n",
    "    KNN_baseline_mean.clear()\n",
    "    KNN_total_Time.clear()\n",
    "    \n",
    "def generateTrainDataSet(test_patienIds, X_train, y_train):\n",
    "    #print(\"test_patienIds: \\n\", test_patienIds)\n",
    "    train_data= originalData[~(originalData.Patient_id.isin(test_patienIds))]\n",
    "    #X_train = originalData[originalData['Patient_id'].isin(patienIds)]\n",
    "    #print(\"Xtrain after isin operation\\n\", train_data)\n",
    "    #X_train=originalData.loc[originalData['Patient_id'] == patienIds]\n",
    "    X_train = train_data[X_columns]\n",
    "    #print(\"x_train sliced\\n\", X_train)\n",
    "    y_train = train_data[y_columns]\n",
    "    #print(\"y_train sliced\\n\", y_train)    \n",
    "    return X_train, y_train\n",
    " \n",
    "def generateTestDataSet(patienIds, X_test, y_test):\n",
    "    print(\"test_patienIds: \\n\", patienIds)\n",
    "    test_data = originalData[originalData['Patient_id'].isin(patienIds)]\n",
    "    X_test = test_data[X_columns]\n",
    "    #print(\"x_test sliced\\n\", X_test)\n",
    "    y_test = test_data[y_columns]\n",
    "    #print(\"y_test sliced\\n\", y_test)\n",
    "    return X_test, y_test\n",
    "\n",
    "# def CalculateSOFAScore(X_train_impute, X_test_impute):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for K-fold algorithm \n",
    "def KFold_patient(model, KforKFold=10,KforKNN=5, fillmethod=\"\"):\n",
    "    start = time.time()# time indicator for how long the Kfold func takes\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    print(\"Datasize\",len(Uniq_ID))\n",
    "    print(\"K Fold of \",KforKFold ,\" folds with KNN =\",KforKNN)\n",
    "    \n",
    "    # initialisation of the array for storing the different intermediate results\n",
    "    accuracy_model = []\n",
    "    F1Score_model = []\n",
    "    baseline_model= []\n",
    "    auroc_model = []\n",
    "    auprc_model = []\n",
    "    physio_accuracy_model = []\n",
    "    f_measure_model = []\n",
    "    utility_score_model = []\n",
    "    mean_train = 0\n",
    "    positivepredictions = []\n",
    "    #The unique id sets have been created and shuffled in a fix manner in the third block, you can just use it here and no more any other manipulation\n",
    "    idSets = np.array_split(Uniq_ID, KforKFold)# divide the ids into K groups\n",
    "    #print(\"Patients number: \", len(Uniq_ID)) #print('idSets arrays',idSets)\n",
    "    #This for loop is for Kfold, calculating the results for K times\n",
    "    \n",
    "    Twrite = time.time()\n",
    "    open(\"test.txt\", \"w\").close() # clear contents of existing file\n",
    "    for i in range(KforKFold):\n",
    "        splitted = \" \".join( repr(e) for e in idSets[i])\n",
    "        file1 = open(\"test.txt\",\"a\")\n",
    "        file1.write(\"\\n\\n\")\n",
    "        file1.write(str(\"[\" +splitted+\"]\"))\n",
    "        file1.write(\"\\n\\n\")\n",
    "        file1.close()\n",
    "    print(\"Time for writing id to file:\", round(time.time()- Twrite,3))\n",
    "    \n",
    "    \n",
    "    for i in range(KforKFold):\n",
    "        Uniq_ID_copy= Uniq_ID.copy()\n",
    "        start1 = time.time()\n",
    "        X_train, X_test, y_train, y_test = flib.clearAllDatasets(X_train, X_test, y_train, y_test) #first clear all the datasets\n",
    "        print(\"for the\",i+1,\"th iteration: \")#,idSets[i])   \n",
    "        t1 = time.time()\n",
    "        X_test,y_test = generateTestDataSet(idSets[i], X_test, y_test)\n",
    "        print(\"Time for splitting id to test:\", round(time.time()- t1,3))\n",
    "        \n",
    "        t2= time.time()\n",
    "        id_sort= Uniq_ID_copy.sort(axis=0)\n",
    "#         print(\"id_sort\", Uniq_ID_copy)\n",
    "       # print(\"train id\", np.delete(Uniq_ID_copy, idSets[i]-1))\n",
    "        X_train, y_train = generateTrainDataSet(idSets[i],X_train, y_train)\n",
    "        print(\"Time for splitting id to train:\", round(time.time()- t2,3))\n",
    "\n",
    "        #printDataset()\n",
    "        #Now the train and test dataset is generated\n",
    "        #we can begin to train the model wit the training set and evaaulate the performance with the test sett   \n",
    "#         X_train = X_train.drop('time', 1) X_test = X_test.drop('time', 1)\n",
    "        X_train=X_train.astype('float64')\n",
    "        X_test=X_test.astype('float64')    \n",
    "        YTest_copy = y_test  # variable of joining the filled data (X) and Y (Train_output) \n",
    "        patientID_ytest = y_test['Patient_id']\n",
    "        y_train = y_train.drop('Patient_id', 1)\n",
    "        y_test = y_test.drop('Patient_id', 1)      \n",
    "        y_train=y_train.astype('float64')\n",
    "        y_test=y_test.astype('float64')\n",
    "        #print('YTest',YTest_copy.head())\n",
    "        \n",
    "        #fill the missing data\n",
    "        if X_train.isnull().values.any() or X_test.isnull().values.any() :\n",
    "            tKNN= time.time()\n",
    "            print(\"X_train or X_test contains NaN values, KNN/mean is performed.\")\n",
    "            #if there is missing value\n",
    "            #\n",
    "            X_train_impute, X_test_impute, fillmethod = flib.KNNfilling(X_train, X_test, KforKNN, fillmethod)\n",
    "            #X_train_impute, X_test_impute,fillmethod = flib.MeanFilling(X_train,X_test, fillmethod)\n",
    "            #check the missing data   \n",
    "            if np.isnan(X_train_impute).any() or np.isnan(X_test_impute).any() :\n",
    "                print(\"X_train_impute or X_test_impute still contains NaN values\")        \n",
    "            else:\n",
    "                print(\"X_train_impute or X_test_impute have all been filled \")\n",
    "            print(\"Time for NaN values filling: \", round(time.time()- tKNN,2) )\n",
    "        else:\n",
    "            print(\"X_train or X_test have all been filled: \")\n",
    "            X_train_impute = X_train\n",
    "            X_test_impute = X_test\n",
    "                 \n",
    "        #Scale the data， uncomment this part for logistic regression only, in other case, put them in comment\n",
    "        model_name = type(model).__name__\n",
    "        if (model_name == 'LogisticRegression'):\n",
    "            print(\"scaled!\")\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            scaler.fit(X_train_impute)\n",
    "            X_train_impute = scaler.transform(X_train_impute)\n",
    "            X_test_impute = scaler.transform(X_test_impute)\n",
    "\n",
    "        #fit the model and predict\n",
    "        model.fit(X_train_impute, y_train)\n",
    "        y_predicted = model.predict(X_test_impute).astype(int)   \n",
    "        y_predicted_probobility = model.predict_proba(X_test_impute) \n",
    "        #transfer the outpu and evalute it\n",
    "#         y_labels = y_test.astype(int).to_numpy()\n",
    "        y_labels = y_test.astype(int).to_numpy()\n",
    "        if(len(y_predicted_probobility[0]) ==2 ):\n",
    "            y_predicted_probobility =  y_predicted_probobility[:,1].round(4)\n",
    "        else:\n",
    "            print(\"columns of y_predicted_probobility is: \",len(y_predicted_probobility[0]))\n",
    "            y_predicted_probobility =  y_predicted_probobility.round(4)\n",
    "        #print(y_labels) \n",
    "        auroc, auprc, physio_accuracy, f_measure, utility_score = evaluate_performance(y_labels, y_predicted, y_predicted_probobility,patientID_ytest) \n",
    "        auroc_model.append(round(auroc,4))\n",
    "        auprc_model.append(round(auprc,4))\n",
    "        physio_accuracy_model.append(round(physio_accuracy,4))\n",
    "        f_measure_model.append(round(f_measure,4))\n",
    "        utility_score_model.append(round(utility_score,4))\n",
    "        positivepredictions.append(np.sum(y_predicted))        \n",
    "        baseline_model.append(round( (1 - float(y_test.mean()) )*100 , 2 ))\n",
    "        print(\"\\ny_test size:\",y_test.shape, '1´s in y_test',y_test.sum())\n",
    "        print(\"The number of 1 (SepsisLabel) in this prediction: \", np.sum(y_predicted))\n",
    "        print(\"Time spent in this KFold iteration\",round( time.time()-start1,2),\"sec.\\n\")\n",
    "        print(\"******************************************************************\")    \n",
    "    print(\"\\nEvaluation parameters of the utiltiy evaluation function:\")\n",
    "    print('auroc of model:', auroc_model)\n",
    "    print('auprc of model:', auprc_model)\n",
    "    print('utility F1 of model:', f_measure_model)\n",
    "    print('Utility accuracy of model:', accuracy_model) \n",
    "    print('Utility score of model:', utility_score_model)\n",
    "    print(\"Positive Prediction: \", positivepredictions)\n",
    "    print('Baseline model:', baseline_model)  \n",
    "    KNN_auroc_mean.append(np.mean(auroc_model))\n",
    "    KNN_auprc_mean.append(np.mean(auprc_model))\n",
    "    KNN_F1Score_mean.append(np.mean(f_measure_model))\n",
    "    KNN_F1Score_std.append(np.std(f_measure_model))\n",
    "    KNN_accuracy_mean.append(np.mean(physio_accuracy_model))\n",
    "    KNN_accuracy_std.append(np.std(physio_accuracy_model))\n",
    "    KNN_UtilityScore_mean.append(np.mean(utility_score_model))\n",
    "    KNN_UtilityScore_std.append(np.std(utility_score_model))\n",
    "    KNN_positiveprediction_mean.append(np.mean(positivepredictions))\n",
    "    KNN_baseline_mean.append(np.mean(baseline_model))\n",
    "    \n",
    "    totalTime=round(time.time()- start,2)\n",
    "    KNN_total_Time.append(totalTime)\n",
    "    print(\"\\nTotal Time spent in  KFold function\",totalTime,\"sec.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Print_DATA():\n",
    "    print(\"Numbers of K:\",len(KNN_accuracy_mean))\n",
    "    print(\"KNN_UtilityScore_mean\", KNN_UtilityScore_mean)\n",
    "    print(\"KNN_UtilityScore_std\", KNN_UtilityScore_std)\n",
    "    print(\"KNN_F1Score_mean\", KNN_F1Score_mean)\n",
    "    print(\"KNN_F1Score_std\", KNN_F1Score_std)\n",
    "    print(\"KNN_auroc_mean\", KNN_auroc_mean)\n",
    "    print(\"KNN_auprc_mean\", KNN_auprc_mean)\n",
    "    print(\"KNN_accuracy_mean\", KNN_accuracy_mean)\n",
    "    print(\"KNN_accuracy_std\", KNN_accuracy_std)\n",
    "    print(\"KNN_positiveprediction_mean\", KNN_positiveprediction_mean)\n",
    "    print(\"KNN_baseline_mean\", KNN_baseline_mean)\n",
    "    print(\"KNN_total_time\", KNN_total_Time)      \n",
    "\n",
    "# def findBestKforKNN(model, KforKFold=10,KforKNNstart=1,KforKNNend=10, stepsize=5):\n",
    "#     if(KforKNNend<=1):\n",
    "#         print(\"K must be a interger larger than 1\")\n",
    "#         return\n",
    "#     KNN_reset()\n",
    "#     step=stepsize\n",
    "#     for i in range(KforKNNstart,KforKNNend+1,step) : \n",
    "#         print(\"KNN of K = \",i)    \n",
    "#         KFold_patient(model,10,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='saga', max_iter=1000,penalty='l1')\n",
    "logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='lbfgs', max_iter=1000)\n",
    "decisionTreeModel = tree.DecisionTreeClassifier(random_state=2)\n",
    "randomForestModel = RandomForestClassifier(random_state=2)\n",
    "XGBoostModel = XGBClassifier(random_state=2, n_jobs=4)\n",
    "#AdaBoostModel = AdaBoostClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../raw_data/raw_data_1000.csv\n",
      "Data isn´t all filled before K-Fold Func\n"
     ]
    }
   ],
   "source": [
    "#fill the missing data with one function\n",
    "print(filename)\n",
    "#print(originalData)\n",
    "if (originalData.isnull().values.any()):\n",
    "    print('Data isn´t all filled before K-Fold Func')\n",
    "#data,fillmethod = flib.linearFillingAll(originalData,1, True)#forwardfilling + fill other missing data with 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasize 1000\n",
      "K Fold of  10  folds with KNN = 5\n",
      "Time for writing id to file: 0.002\n",
      "for the 1 th iteration: \n",
      "test_patienIds: \n",
      " [291 215 113 545 697 542 794 673 660 340 299 646 822 497  93 290 207 212\n",
      " 633 219 842 601 670  63 846  23 561 508 267 645 795 755 868 543 433 301\n",
      " 472 649 100 976  65 556 380 246 153 799 277 128 471 252 990 483 309 581\n",
      " 605 308 956 506 685 154 713 573 358 540  67 712 703 342 514 458 147 493\n",
      " 112 486 349 530 987 961 470 323 797 357 579 878  44 300 121  92 399 973\n",
      " 950 650 970 366 647 464 444 441 684 374]\n",
      "Time for splitting id to test: 0.006\n",
      "Time for splitting id to train: 0.011\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "Time for NaN values filling:  260.54\n",
      "\n",
      "y_test size: (3649, 1) 1´s in y_test SepsisLabel    47.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  50\n",
      "Time spent in this KFold iteration 261.6 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 2 th iteration: \n",
      "test_patienIds: \n",
      " [688 739 833 577 664 926 217 899 659 159 455 807 902  43 662 283   3 418\n",
      " 818 995 752 388 230 641 974 190 199 969 107 106 901  71 518 907 467 516\n",
      " 869 509 578 152 710 616  10 584 597 781 229 866 250 898 736 406  11 788\n",
      " 966  50 489 921 825 449 873 302 141 628 435 867 379 312 285 313 378 362\n",
      " 672 500 674 526  81 102 656 284 812 391  88 551 296 307 326 696 462 591\n",
      "  27 488 879 623 915 746 762 101 745 440]\n",
      "Time for splitting id to test: 0.005\n",
      "Time for splitting id to train: 0.012\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "Time for NaN values filling:  249.91\n",
      "\n",
      "y_test size: (4344, 1) 1´s in y_test SepsisLabel    82.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  294\n",
      "Time spent in this KFold iteration 251.38 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 3 th iteration: \n",
      "test_patienIds: \n",
      " [533 618 998 428 800  14 903 265 411 287  64  30 947  34 894 885 356 728\n",
      " 786 136 887 351 134 209 274 808 295  52 244  16 139 310 179 676   8 993\n",
      "  36 124 663 661 329 547 220  13 377 167 876 999 270 682 407 355   7 345\n",
      "  57 642 557 130 332 614 157 437 439 760 731 850 341 783  56 849 232 787\n",
      " 198 211 655 844 206 859 451 815 784 279 978 837 243 613 480 117 352 896\n",
      "  60 416 806 512 694 891 767 737  91  74]\n",
      "Time for splitting id to test: 0.003\n",
      "Time for splitting id to train: 0.012\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n"
     ]
    }
   ],
   "source": [
    "KFold_patient(decisionTreeModel,10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCurrentResult(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = da."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
