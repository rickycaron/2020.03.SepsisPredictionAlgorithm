{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code to find the most suitable K value for the KNN filling algorithm\n",
    "Since Logistic regression performs and worst among all algorithm, we don't use it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "# Cross Validation Classification Accuracy\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing \n",
    "from sklearn.impute import KNNImputer\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "#import faiss\n",
    "from numpy import isnan\n",
    "#import matplotlib.pyplot as plot\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn import tree\n",
    "import statistics\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# plotting errorbar graph for visual representation of the performance of the classifiers\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import Affine2D\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "import shutil\n",
    "import os\n",
    "from os import path\n",
    "import ipynb.fs.full.our_functions_library as flib\n",
    "from our_evaluate_sepsis_score import evaluate_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: (1552210, 43)\n",
      "Patient id size: 40336\n"
     ]
    }
   ],
   "source": [
    "# Global initialization, get all the data from file and generate all the needed variable\n",
    "filename = 'raw_data/raw_data_all.csv' # use raw dataset\n",
    "#filename = 'data.csv' # use raw dataset\n",
    "originalData = read_csv(filename) # read csv data into DataFrame var raw\n",
    "print(\"Data size:\",originalData.shape)\n",
    "Original_Uniq_ID= np.unique(originalData['Patient_id']) \n",
    "Uniq_ID = Original_Uniq_ID.copy()\n",
    "print('Patient id size:',len(Uniq_ID))\n",
    "X_columns = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2','BaseExcess', 'HCO3', 'FiO2', 'pH', \n",
    "             'PaCO2', 'SaO2', 'AST', 'BUN','Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
    "             'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium','Bilirubin_total', 'TroponinI', 'Hct', \n",
    "             'Hgb', 'PTT', 'WBC','Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2','HospAdmTime',\n",
    "             'ICULOS', 'Patient_id', 'time']\n",
    "y_columns = ['Patient_id', 'SepsisLabel']\n",
    "\n",
    "# To test if these 3 columns is useful\n",
    "# originalData = originalData.drop(['Unit1', 'Unit2', 'EtCO2'], axis=1)\n",
    "# X_columns.remove('Unit1')\n",
    "# X_columns.remove( 'Unit2')\n",
    "# X_columns.remove( 'EtCO2')\n",
    "\n",
    "# Initialize the empty array X_train, X_test, y_train, y_test\n",
    "X_train = pd.DataFrame(columns = X_columns)\n",
    "X_test = pd.DataFrame(columns = X_columns)\n",
    "y_train = pd.DataFrame(columns = y_columns)\n",
    "y_test = pd.DataFrame(columns = y_columns)\n",
    "# Below are the lists for KNN results\n",
    "\n",
    "KNN_UtilityScore_mean = []\n",
    "KNN_UtilityScore_std = []\n",
    "\n",
    "KNN_F1Score_mean = []\n",
    "KNN_F1Score_std = []\n",
    "\n",
    "KNN_auroc_mean = []\n",
    "KNN_auprc_mean = []\n",
    "\n",
    "KNN_accuracy_mean = []\n",
    "KNN_accuracy_std = []\n",
    "\n",
    "KNN_positiveprediction_mean = []\n",
    "KNN_baseline_mean = [ ]\n",
    "\n",
    "\n",
    "fillmethod =\"\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They are the same. Uniq id hasn't been shuffled, and it will be shuffeld now.\n",
      "The original uniq id set is:\n",
      " [    1     2     3 ... 40334 40335 40336]\n",
      "Uniq id:************************************\n",
      "The fixed shuffelld id set, it should be 211 275 153 189 184 110 124  49 345...\n",
      " [ 4926 30520 22202 ...  5563  6003  3707]\n"
     ]
    }
   ],
   "source": [
    "#This block will shuffle the id sets of patients in a fix manner, so for every time you run the code, the dataset and trainset are always the same.\n",
    "seed = 2\n",
    "random.seed(seed)\n",
    "if(np.array_equal(Original_Uniq_ID,Uniq_ID) ):\n",
    "    print(\"They are the same. Uniq id hasn't been shuffled, and it will be shuffeld now.\")   \n",
    "    random.shuffle(Uniq_ID)# randomly sorted the patient IDs    \n",
    "else:\n",
    "    print(\"They are not the same. Uniq_id has already been shuffled.\")    \n",
    "print(\"The original uniq id set is:\\n\",Original_Uniq_ID)\n",
    "print(\"Uniq id:************************************\")\n",
    "print(\"The fixed shuffelld id set, it should be 211 275 153 189 184 110 124  49 345...\\n\",Uniq_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fill the missing data with one function\n",
    "# print(filename)\n",
    "# #print(originalData)\n",
    "# if (originalData.isnull().values.any()):\n",
    "#     print('There is data missing in the original data set')\n",
    "# dataByPatient = originalData.groupby('Patient_id') # data grouped by Patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will clear everything in the trainng and test dataset\n",
    "def clearAllDatasets():\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    if not X_train.empty: \n",
    "        X_train = X_train[0:0]\n",
    "    if not X_test.empty:\n",
    "        X_test = X_test[0:0]\n",
    "    if not y_train.empty:\n",
    "        y_train = y_train[0:0]\n",
    "    if not y_test.empty:\n",
    "        y_test = y_test[0:0]\n",
    "    \n",
    "def printDataset():\n",
    "    print('X train shape:',X_train.shape)\n",
    "    print(X_train)\n",
    "    print( 'Y train shape:',y_train.shape)\n",
    "    print(y_train)\n",
    "    print('X test shape:',X_test.shape)\n",
    "    print(X_test)\n",
    "    print( 'Y test shape:',y_test.shape)\n",
    "    print(y_test)\n",
    "    \n",
    "def printDatasetType():\n",
    "    print('X_train type:',type(X_train),'y_train type:',type(y_train) )\n",
    "    print('X test shape:',type(X_test),'Y test shape:',type(y_test) )\n",
    "    print('X_train data type:',(X_train.dtypes),'y_train data type:',(y_train.dtypes) )\n",
    "    print('X_test data type:',(X_test.dtypes),'Y_test data type:',(y_test.dtypes) )\n",
    "    \n",
    "def KNN_reset():\n",
    "    #KNN with different K size, \n",
    "    KNN_UtilityScore_mean.clear()\n",
    "    KNN_UtilityScore_std.clear()\n",
    "    KNN_F1Score_mean.clear()\n",
    "    KNN_F1Score_std.clear()\n",
    "    KNN_auroc_mean.clear()\n",
    "    KNN_auprc_mean.clear()\n",
    "    KNN_accuracy_mean.clear()\n",
    "    KNN_accuracy_std.clear()\n",
    "    KNN_positiveprediction_mean.clear()\n",
    "    KNN_baseline_mean.clear()\n",
    "    \n",
    "def generateTrainDataSet(patienIds):\n",
    "    global X_train, y_train\n",
    "    for i in patienIds:\n",
    "#     print('Patient_id',i,':\\n',dataByPatient.get_group(i),'\\n')\n",
    "        X_train = X_train.append(dataByPatient.get_group(i).loc[:, X_columns])\n",
    "        y_train = y_train.append(dataByPatient.get_group(i).loc[:, y_columns])\n",
    "    return X_train, y_train\n",
    " \n",
    "def generateTestDataSet(patienIds):\n",
    "    global X_test, y_test\n",
    "    for i in patienIds:\n",
    "#     print('Patient_id',i,':\\n',dataByPatient.get_group(i),'\\n')\n",
    "        X_test = X_test.append(dataByPatient.get_group(i).loc[:, X_columns])\n",
    "        y_test = y_test.append(dataByPatient.get_group(i).loc[:, y_columns]) \n",
    "    return X_test, y_test\n",
    "\n",
    "#Functions below are filling the missing data\n",
    "#This function perform the KNN missing data filling for \n",
    "# import numba as nb\n",
    "# @nb.jit\n",
    "def KNNfilling(trainData,testData,K= 5, fillmethod=\"\"):\n",
    "    imputer = KNNImputer(n_neighbors = K)\n",
    "    #imputer = FaissKNeighbors(k=K)\n",
    "    # fit \n",
    "    imputer.fit(trainData)\n",
    "    #transfer\n",
    "#     x_train_impute=imputer.transform(trainData).round(3)\n",
    "#     x_test_impute=imputer.transform(testData).round(3)\n",
    "    x_train_impute=imputer.transform(trainData)\n",
    "    x_test_impute=imputer.transform(testData)\n",
    "    fillmethod= \"KnnFill\"\n",
    "    return x_train_impute, x_test_impute, fillmethod   #This may cause error when the data is very large in size\n",
    "\n",
    "def CalculateSOFAScore(X_train_impute, X_test_impute):\n",
    "    pass\n",
    "\n",
    "#fill the missing data by the overall mean value \n",
    "def MeanFilling(trainData,testData, fillmethod, overall = True):\n",
    "    if(overall):\n",
    "        data_concat = pd.concat((trainData, testData))\n",
    "        fillingmean = data_concat.mean().round(2)  \n",
    "        print(\"fill with overall data mean\")\n",
    "    else:\n",
    "        fillingmean = trainData.mean().round(2)\n",
    "        print(\"fill with training data mean\")\n",
    "    train_mean_filled = trainData.fillna(fillingmean)\n",
    "    test_mean_filled = testData.fillna(fillingmean)\n",
    "    fillmethod= \"MeanFill\"\n",
    "    #print(train_mean_filled) \n",
    "    #print(test_mean_filled)\n",
    "    return train_mean_filled, test_mean_filled, fillmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteToFiles(X_test_impute,y_test, NFold, fillmethod):\n",
    "    x= pd.DataFrame(data=X_test_impute, columns=X_columns)\n",
    "    y= pd.DataFrame(data=y_test, columns=y_columns)\n",
    "    # tot= x.join(y)\n",
    "    x.merge(y, how='inner', on='Patient_id')\n",
    "    patient_size=np.unique(x['Patient_id'])\n",
    "#     print(patient_size)\n",
    "#     print(int(patient_size[2]))\n",
    "    dirName=r'C:\\Users\\r0631\\Documents\\K-Fold\\filled_data/'+str(fillmethod)+'/Fold'+str(NFold+1)\n",
    "    if os.path.exists(dirName):\n",
    "        shutil.rmtree(dirName)  # remove existing directory\n",
    "    os.makedirs(dirName)\n",
    "    for ind in range(len(patient_size)):\n",
    "        #filename=r'output/Fold'+str(NFold+1)+'/p'+str(ind)+'.psv'\n",
    "        id =int(patient_size[ind])\n",
    "        filename=dirName+'/p'+str(id)+'.psv'\n",
    "        patient = x.loc[x['Patient_id'] == id]\n",
    "        patient.to_csv (filename, index = False, header=True, sep='|')\n",
    "    print('Fold',NFold,'written away')\n",
    "    \n",
    "def CalcMean_Std (Data):\n",
    "    print(Data)\n",
    "    mean= np.mean(Data, axis=0)\n",
    "    np.set_printoptions(precision=3, suppress=True)\n",
    "    print('numpy mean\\n',mean)\n",
    "    Data_std = Data.std(axis = 0) \n",
    "    print('Data_mean\\n',Data_std.round(3))\n",
    "    \n",
    "def plotKNNResultFigure(KValuestart,KvalueEnd,yValues,title,xlabel,ylabel):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(range(KValuestart,KvalueEnd,5),yValues,color = 'blue',linestyle='dashed', \n",
    "             marker='o',markerfacecolor='red', markersize=10)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    print(\"Maximum \",ylabel,\":-\",max(yValues),\"at K =\", 1 + yValues.index(max(yValues)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for K-fold algorithm, Before this step the missing data has been filled, \n",
    "def KFold_patient(model, KforKFold=10,KforKNN=5, fillmethod=\"\"):\n",
    "    start = time.time()# time indicator for how long the Kfold func takes\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    print(\"K Fold of \",KforKFold ,\" folds with KNN =\",KforKNN)\n",
    "    # initialisation of the array for storing the different intermediate results\n",
    "    accuracy_model = []\n",
    "    F1Score_model = []\n",
    "    baseline_model= []\n",
    "    auroc_model = []\n",
    "    auprc_model = []\n",
    "    physio_accuracy_model = []\n",
    "    f_measure_model = []\n",
    "    utility_score_model = []\n",
    "    mean_train = 0\n",
    "    positivepredictions = []\n",
    "    #The unique id sets have been created and shuffled in a fix manner in the third block, you can just use it here and no more any other manipulation\n",
    "    idSets = np.array_split(Uniq_ID, KforKFold)# divide the ids into K groups\n",
    "    #print(\"Patients number: \", len(Uniq_ID)) #print('idSets arrays',idSets)\n",
    "    #This for loop is for Kfold, calculating the results for K times\n",
    "    for i in range(KforKFold):\n",
    "        start1 = time.time()\n",
    "        clearAllDatasets() #first clear all the datasets\n",
    "        print(\"for the\",i+1,\"th iteration\",idSets[i])   \n",
    "        X_test,y_test = generateTestDataSet(idSets[i])\n",
    "        for j in range(KforKFold):\n",
    "            if j != i:\n",
    "                 X_train, y_train = generateTrainDataSet(idSets[j]) \n",
    "        #printDataset()\n",
    "        #Now the train and test dataset is generated\n",
    "        #we can begin to train the model wit the training set and evaaulate the performance with the test sett   \n",
    "#         X_train = X_train.drop('time', 1) X_test = X_test.drop('time', 1)\n",
    "        X_train=X_train.astype('float64')\n",
    "        X_test=X_test.astype('float64')    \n",
    "        YTest_copy = y_test  # variable of joining the filled data (X) and Y (Train_output) \n",
    "        patientID_ytest = y_test['Patient_id']\n",
    "        y_train = y_train.drop('Patient_id', 1)\n",
    "        y_test = y_test.drop('Patient_id', 1)      \n",
    "        y_train=y_train.astype('float64')\n",
    "        y_test=y_test.astype('float64')\n",
    "        #print('YTest',YTest_copy.head())\n",
    "        \n",
    "        #fill the missing data\n",
    "        if X_train.isnull().values.any() or X_test.isnull().values.any() :\n",
    "            print(\"X_train or X_test contains NaN values, KNN/mean is performed.\")\n",
    "            #if there is missing value\n",
    "            X_train_impute, X_test_impute, fillmethod = KNNfilling(X_train, X_test, KforKNN, fillmethod)\n",
    "            #X_train_impute, X_test_impute,fillmethod = MeanFilling(X_train,X_test, fillmethod)\n",
    "            #check the missing data   \n",
    "            if np.isnan(X_train_impute).any() or np.isnan(X_test_impute).any() :\n",
    "                print(\"X_train_impute or X_test_impute still contains NaN values\")        \n",
    "            else:\n",
    "                print(\"X_train_impute or X_test_impute have all been filled \")  \n",
    "        else:\n",
    "            print(\"X_train or X_test have all been filled \")\n",
    "            X_train_impute = X_train\n",
    "            X_test_impute = X_test\n",
    "                 \n",
    "        #Scale the data， uncomment this part for logistic regression only, in other case, put them in comment\n",
    "        print(\"scaled!\")\n",
    "        scaler = preprocessing.StandardScaler()\n",
    "        scaler.fit(X_train_impute)\n",
    "        X_train_impute = scaler.transform(X_train_impute)\n",
    "        X_test_impute = scaler.transform(X_test_impute)\n",
    "\n",
    "        #fit the model and predict\n",
    "        model.fit(X_train_impute, y_train)\n",
    "        y_predicted = model.predict(X_test_impute)   \n",
    "        y_predicted_probobility = model.predict_proba(X_test_impute) \n",
    "        #transfer the outpu and evalute it\n",
    "        y_labels = y_test.astype(int).to_numpy()\n",
    "        y_predicted = y_predicted.astype(int)\n",
    "        y_predicted_probobility =  y_predicted_probobility[:,1].round(4)\n",
    "        #print(y_labels)      \n",
    "        auroc, auprc, physio_accuracy, f_measure, utility_score = evaluate_performance(y_labels, y_predicted, y_predicted_probobility,patientID_ytest)\n",
    "#         print(\"\\nauroc\",round(auroc,4),\"auprc\",round(auprc,4),\"util_accuracy\",round(accuracy1,4))\n",
    "#         print(\"f_measure\",round(f_measure,4),\"utility_score\",round(utility_score,4))  \n",
    "        auroc_model.append(round(auroc,4))\n",
    "        auprc_model.append(round(auprc,4))\n",
    "        physio_accuracy_model.append(round(physio_accuracy,4))\n",
    "        f_measure_model.append(round(f_measure,4))\n",
    "        utility_score_model.append(round(utility_score,4))\n",
    "        positivepredictions.append(np.sum(y_predicted))\n",
    "\n",
    "        num_rows= X_test_impute.shape[0]\n",
    "        scores = np.zeros(num_rows).astype('float64')# score parameter:output from get_sepsis_score\n",
    "        labels = np.zeros(num_rows).astype('float64')\n",
    "        #WriteToFiles(X_train_impute,YTest_copy,i, fillmethod)\n",
    "        #CalcMean_Std(X_train_impute)\n",
    "        #take down the results\n",
    "        accuracy_model.append((accuracy_score(y_test, y_predicted, normalize=True)*100).round(2))\n",
    "        F1Score_model.append((f1_score(y_test, y_predicted)*100).round(2))\n",
    "        baseline_model.append(round( (1 - float(y_test.mean()) )*100 , 2 ))\n",
    "        print(\"\\ny_test size:\",y_test.shape, '1´s in y_test',y_test.sum())\n",
    "        #baseline_model.append(((1-y_test.mean())*100).round(2))\n",
    "        print(\"The number of 1 (SepsisLabel) in this prediction: \", np.sum(y_predicted))\n",
    "    #     print(accuracy_model)\n",
    "    #     print(F1Score_model)    \n",
    "        end1 = time.time()\n",
    "        print(\"Time spent in this KFold iteration\",round(end1- start1,2),\"sec.\\n\")\n",
    "        print(\"******************************************************************\")\n",
    "    print('Accuracy model:', accuracy_model)\n",
    "    print('F1_score model:', F1Score_model)\n",
    "    print('Baseline model:', baseline_model)\n",
    "    \n",
    "    print(\"\\nEvaluation parameters of the utiltiy evaluation function:\")\n",
    "    print('auroc of model:', auroc_model)\n",
    "    print('auprc of model:', auprc_model)\n",
    "    print('Utility accuracy of model:', accuracy_model)\n",
    "    print('utility F1 of model:', f_measure_model)\n",
    "    print('Utility score of model:', utility_score_model)\n",
    "    \n",
    "    KNN_UtilityScore_mean.append(np.mean(utility_score_model))\n",
    "    KNN_UtilityScore_std.append(np.std(utility_score_model))\n",
    "    \n",
    "    KNN_F1Score_mean.append(np.mean(f_measure_model))\n",
    "    KNN_F1Score_std.append(np.std(f_measure_model))\n",
    "    \n",
    "    KNN_auroc_mean.append(np.mean(auroc_model))\n",
    "    KNN_auprc_mean.append(np.mean(auprc_model))\n",
    "    \n",
    "    KNN_accuracy_mean.append(np.mean(physio_accuracy_model))\n",
    "    KNN_accuracy_std.append(np.std(physio_accuracy_model))\n",
    "    \n",
    "    KNN_positiveprediction_mean.append(np.mean(positivepredictions))\n",
    "    KNN_baseline_mean.append(np.mean(baseline_model))\n",
    "    \n",
    "    print(\"\\nTotal Time spent in  KFold function\",round(time.time()- start,2),\"sec.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def displayCurrentResult(KforKNNstart,KforKNNend):\n",
    "    print(\"KNN_UtilityScore_mean\",KNN_UtilityScore_mean)\n",
    "    print(\"KNN_UtilityScore_std\",KNN_UtilityScore_std)\n",
    "    print(\"KNN_F1Score_mean\",KNN_F1Score_mean)\n",
    "    print(\"KNN_F1Score_std\",KNN_F1Score_std)\n",
    "    print(\"KNN_auroc_mean\",KNN_auroc_mean)\n",
    "    print(\"KNN_auprc_mean\",KNN_auprc_mean)\n",
    "    print(\"KNN_accuracy_mean\",KNN_accuracy_mean)\n",
    "    print(\"KNN_accuracy_std\",KNN_accuracy_std)\n",
    "    print(\"KNN_positiveprediction_mean\",KNN_positiveprediction_mean)\n",
    "    print(\"KNN_baseline_mean\",KNN_baseline_mean)        \n",
    "    print(len(KNN_accuracy_mean))\n",
    "    print(len(KNN_accuracy_std))\n",
    "    print(len(KNN_F1Score_mean))\n",
    "    print(len(KNN_F1Score_std))\n",
    "    print(len(KNN_positiveprediction_mean))\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_UtilityScore_mean,\"Mean Utility Score vs K\",xlabel='K',ylabel=\"mean Utility Score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_UtilityScore_std,\"std Utility Score vs K\",xlabel='K',ylabel=\"std Utility Score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_F1Score_mean,\"Mean F1 score vs K\",xlabel='K',ylabel=\"Mean F1 score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_F1Score_std,\"Std F1 score vs K\",xlabel='K',ylabel=\"Std F1 score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_accuracy_mean,\"Mean Accuracy vs K\",xlabel='K',ylabel=\"Mean Accuracy\")      \n",
    "\n",
    "def findBestKforKNN(model, KforKFold=10,KforKNNstart=1,KforKNNend=10):\n",
    "    if(KforKNNend<=1):\n",
    "        print(\"K must be a interger larger than 1\")\n",
    "        return\n",
    "    KNN_reset()\n",
    "    for i in range(KforKNNstart,KforKNNend+1) : \n",
    "        print(\"KNN of K = \",i)    \n",
    "        KFold_patient(model,10,i)\n",
    "    print(\"Now all the training is finished.\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_UtilityScore_mean,\"Mean Utility Score vs K\",xlabel='K',ylabel=\"mean Utility Score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_UtilityScore_std,\"std Utility Score vs K\",xlabel='K',ylabel=\"std Utility Score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_F1Score_mean,\"Mean F1 score vs K\",xlabel='K',ylabel=\"Mean F1 score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_F1Score_std,\"Std F1 score vs K\",xlabel='K',ylabel=\"Std F1 score\")\n",
    "    plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_accuracy_mean,\"Mean Accuracy vs K\",xlabel='K',ylabel=\"Mean Accuracy\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is how to train the model\n",
    "#logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='saga', max_iter=1000,penalty='l1')\n",
    "logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='lbfgs', max_iter=1000)\n",
    "decisionTreeModel = tree.DecisionTreeClassifier(random_state=2)\n",
    "randomForestModel = RandomForestClassifier(random_state=2)\n",
    "XGBoostModel = XGBClassifier(random_state=2)\n",
    "#AdaBoostModel = AdaBoostClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data/raw_data_all.csv\n",
      "Data isn´t all filled before K-Fold Func\n",
      "filling using Forward filling\n"
     ]
    }
   ],
   "source": [
    "#fill the missing data with one function\n",
    "print(filename)\n",
    "#print(originalData)\n",
    "if (originalData.isnull().values.any()):\n",
    "    print('Data isn´t all filled before K-Fold Func')\n",
    "data,fillmethod = flib.linearFillingAll(originalData,1, True)#forwardfilling + fill other missing data with 0\n",
    "dataByPatient = data.groupby('Patient_id') # data grouped by Patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dataByPatient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Logistic Regression\")\n",
    "KFold_patient(decisionTreeModel,10, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Decision tree\")\n",
    "#KFold_patient(randomForestModel,10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findBestKforKNN(logisticRegressionModel,10,1,10)\n",
    "# findBestKforKNN(XGBoostModel,10,110,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# findBestKforKNN(decisionTreeModel,10,1,10)\n",
    "# os.system('\\a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCurrentResult(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
