{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code to find the most suitable K value for the KNN filling algorithm\n",
    "Since Logistic regression performs and worst among all algorithm, we don't use it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "# Cross Validation Classification Accuracy\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing \n",
    "from sklearn.impute import KNNImputer\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "#import faiss\n",
    "from numpy import isnan\n",
    "#import matplotlib.pyplot as plot\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn import tree\n",
    "import statistics\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# plotting errorbar graph for visual representation of the performance of the classifiers\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import Affine2D\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "import shutil\n",
    "import os\n",
    "from os import path\n",
    "# import ipynb.fs.full.our_functions_library as flib\n",
    "import our_functions_library as flib\n",
    "from our_evaluate_sepsis_score import evaluate_performance\n",
    "import numba\n",
    "from numba import jit, njit, cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global initialization, get all the data from file and generate all the needed variable\n",
    "filename = '../../raw_data/raw_data_400.csv' # use raw dataset\n",
    "#filename = 'data.csv' # use raw dataset\n",
    "originalData = read_csv(filename) # read csv data into DataFrame var raw\n",
    "print(\"Data size:\",originalData.shape)\n",
    "Original_Uniq_ID= np.unique(originalData['Patient_id']) \n",
    "Uniq_ID = Original_Uniq_ID.copy()\n",
    "print('Patient id size:',len(Uniq_ID))\n",
    "X_columns = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2','BaseExcess', 'HCO3', 'FiO2', 'pH', \n",
    "             'PaCO2', 'SaO2', 'AST', 'BUN','Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
    "             'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium','Bilirubin_total', 'TroponinI', 'Hct', \n",
    "             'Hgb', 'PTT', 'WBC','Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2','HospAdmTime',\n",
    "             'ICULOS', 'Patient_id', 'time']\n",
    "y_columns = ['Patient_id', 'SepsisLabel']\n",
    "\n",
    "# To test if these 3 columns is useful\n",
    "# originalData = originalData.drop(['Unit1', 'Unit2', 'EtCO2'], axis=1)\n",
    "# X_columns.remove('Unit1')\n",
    "# X_columns.remove( 'Unit2')\n",
    "# X_columns.remove( 'EtCO2')\n",
    "\n",
    "# Initialize the empty array X_train, X_test, y_train, y_test\n",
    "X_train = pd.DataFrame(columns = X_columns)\n",
    "X_test = pd.DataFrame(columns = X_columns)\n",
    "y_train = pd.DataFrame(columns = y_columns)\n",
    "y_test = pd.DataFrame(columns = y_columns)\n",
    "\n",
    "# store the X & y train/test in array for easy access\n",
    "globaldata = []\n",
    "globaldata.append(X_train)\n",
    "globaldata.append(y_train)\n",
    "globaldata.append(X_test)\n",
    "globaldata.append(y_test)\n",
    "# Below are the lists for KNN results\n",
    "\n",
    "KNN_UtilityScore_mean = []\n",
    "KNN_UtilityScore_std = []\n",
    "\n",
    "KNN_F1Score_mean = []\n",
    "KNN_F1Score_std = []\n",
    "\n",
    "KNN_auroc_mean = []\n",
    "KNN_auprc_mean = []\n",
    "\n",
    "KNN_accuracy_mean = []\n",
    "KNN_accuracy_std = []\n",
    "\n",
    "KNN_positiveprediction_mean = []\n",
    "KNN_sepsisLabelRatio_mean = []\n",
    "\n",
    "KNN_baseline_mean = [ ]\n",
    "KNN_total_Time= [ ]\n",
    "\n",
    "\n",
    "fillmethod =\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block will shuffle the id sets of patients in a fix manner, so for every time you run the code, the dataset and trainset are always the same.\n",
    "seed = 8\n",
    "random.seed(seed)\n",
    "if(np.array_equal(Original_Uniq_ID,Uniq_ID) ):\n",
    "    print(\"They are the same. Uniq id hasn't been shuffled, and it will be shuffeld now.\")   \n",
    "    random.shuffle(Uniq_ID)# randomly sorted the patient IDs    \n",
    "else:\n",
    "    print(\"They are not the same. Uniq_id has already been shuffled.\")    \n",
    "print(\"The original uniq id set is:\\n\",Original_Uniq_ID[1:20])\n",
    "print(\"Uniq id:************************************\")\n",
    "print(\"The fixed shuffelld id set, it should be 211 275 153 189 184 110 124  49 345...\\n\",Uniq_ID[1:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fill the missing data with one function\n",
    "# print(filename)\n",
    "# #print(originalData)\n",
    "# if (originalData.isnull().values.any()):\n",
    "#     print('There is data missing in the original data set')\n",
    "# dataByPatient = originalData.groupby('Patient_id') # data grouped by Patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_reset():\n",
    "    #KNN with different K size, \n",
    "    KNN_UtilityScore_mean.clear()\n",
    "    KNN_UtilityScore_std.clear()\n",
    "    KNN_F1Score_mean.clear()\n",
    "    KNN_F1Score_std.clear()\n",
    "    KNN_auroc_mean.clear()\n",
    "    KNN_auprc_mean.clear()\n",
    "    KNN_accuracy_mean.clear()\n",
    "    KNN_accuracy_std.clear()\n",
    "    KNN_positiveprediction_mean.clear()\n",
    "    KNN_sepsisLabelRatio_mean.clear() #array for storing the mean of the sepsislabel ratio (predict/true)\n",
    "    KNN_baseline_mean.clear()\n",
    "    KNN_total_Time.clear()\n",
    "\n",
    "def generateTrainDataSet(test_patienIds, X_train, y_train):\n",
    "    train_data= originalData[~(originalData.Patient_id.isin(test_patienIds))]\n",
    "    X_train = train_data[X_columns]\n",
    "    y_train = train_data[y_columns]\n",
    "    return X_train, y_train\n",
    " \n",
    "def generateTestDataSet(patienIds, X_test, y_test):\n",
    "    #print(\"test_patienIds: \\n\", patienIds)\n",
    "    test_data = originalData[originalData['Patient_id'].isin(patienIds)]\n",
    "    X_test = test_data[X_columns]\n",
    "    y_test = test_data[y_columns]\n",
    "    return X_test, y_test\n",
    "\n",
    "# def CalculateSOFAScore(X_train_impute, X_test_impute):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for K-fold algorithm, Before this step the missing data has been filled, \n",
    "def KFold_patient(model, KforKFold=10,KforKNN=5, fillmethod=\"\"):\n",
    "    start = time.time()# time indicator for how long the Kfold func takes\n",
    "    X_train = globaldata[0]\n",
    "    y_train = globaldata[1]\n",
    "    X_test = globaldata[2]\n",
    "    y_test = globaldata[3]\n",
    "    print(\"Datasize\",len(Uniq_ID))\n",
    "    print(\"K Fold of \",KforKFold ,\" folds with KNN =\",KforKNN)\n",
    "    \n",
    "    # initialisation of the array for storing the different intermediate results\n",
    "    accuracy_model = []\n",
    "    F1Score_model = []\n",
    "    baseline_model= []\n",
    "    auroc_model = []\n",
    "    auprc_model = []\n",
    "    physio_accuracy_model = []\n",
    "    f_measure_model = []\n",
    "    utility_score_model = []\n",
    "    mean_train = 0\n",
    "    positivepredictions = []\n",
    "    predictionsRatio = []\n",
    "\n",
    "    #The unique id sets have been created and shuffled in a fix manner in the third block, you can just use it here and no more any other manipulation\n",
    "    idSets = np.array_split(Uniq_ID, KforKFold)# divide the ids into K groups\n",
    "    #print(\"Patients number: \", len(Uniq_ID)) #print('idSets arrays',idSets)\n",
    "    #This for loop is for Kfold, calculating the results for K times\n",
    "    for i in range(KforKFold):\n",
    "        start1 = time.time()\n",
    "        X_train, X_test, y_train, y_test = flib.clearAllDatasets(X_train, X_test, y_train, y_test) #first clear all the datasets\n",
    "        print(\"for the\",i+1,\"th iteration\",idSets[i])   \n",
    "        t1 = time.time()\n",
    "        X_test,y_test = generateTestDataSet(idSets[i], X_test, y_test)\n",
    "        print(\"Time for splitting id to test:\", round(time.time()- t1,2))\n",
    "        \n",
    "        t2= time.time()\n",
    "        X_train, y_train = generateTrainDataSet(idSets[i], X_train, y_train)\n",
    "        print(\"Time for splitting id to train:\", round(time.time()- t2,2))\n",
    "\n",
    "        #printDataset()\n",
    "        #Now the train and test dataset is generated\n",
    "        #we can begin to train the model wit the training set and evaaulate the performance with the test sett   \n",
    "#         X_train = X_train.drop('time', 1) X_test = X_test.drop('time', 1)\n",
    "        X_train=X_train.astype('float64')\n",
    "        X_test=X_test.astype('float64')    \n",
    "        YTest_copy = y_test  # variable of joining the filled data (X) and Y (Train_output) \n",
    "        patientID_ytest = y_test['Patient_id']\n",
    "        y_train = y_train.drop('Patient_id', 1)\n",
    "        y_test = y_test.drop('Patient_id', 1)      \n",
    "        y_train=y_train.astype('float64')\n",
    "        y_test=y_test.astype('float64')\n",
    "        #print('YTest',YTest_copy.head())\n",
    "        \n",
    "        #fill the missing data\n",
    "        if X_train.isnull().values.any() or X_test.isnull().values.any() :\n",
    "            print(\"X_train or X_test contains NaN values, KNN/mean is performed.\")\n",
    "            #if there is missing value\n",
    "            X_train_impute, X_test_impute, fillmethod = flib.KNNfilling(X_train, X_test, KforKNN, fillmethod)\n",
    "            #X_train_impute, X_test_impute,fillmethod = flib.MeanFilling(X_train,X_test, fillmethod)\n",
    "            #check the missing data   \n",
    "            if np.isnan(X_train_impute).any() or np.isnan(X_test_impute).any() :\n",
    "                print(\"X_train_impute or X_test_impute still contains NaN values\")        \n",
    "            else:\n",
    "                print(\"X_train_impute or X_test_impute have all been filled \")  \n",
    "        else:\n",
    "            print(\"X_train or X_test have all been filled \")\n",
    "            X_train_impute = X_train\n",
    "            X_test_impute = X_test\n",
    "                 \n",
    "        #Scale the data， uncomment this part for logistic regression only, in other case, put them in comment\n",
    "        model_name = type(model).__name__\n",
    "        if (model_name == 'LogisticRegression'):\n",
    "            print(\"scaled!\")\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            scaler.fit(X_train_impute)\n",
    "            X_train_impute = scaler.transform(X_train_impute)\n",
    "            X_test_impute = scaler.transform(X_test_impute)\n",
    "\n",
    "        #fit the model and predict\n",
    "        model.fit(X_train_impute, y_train)\n",
    "        y_predicted = model.predict(X_test_impute)   \n",
    "        y_predicted_probobility = model.predict_proba(X_test_impute) \n",
    "        #transfer the outpu and evalute it\n",
    "        y_labels = y_test.astype(int).to_numpy()\n",
    "        y_predicted = y_predicted.astype(int)\n",
    "        if(len(y_predicted_probobility[0]) ==2 ):\n",
    "            y_predicted_probobility =  y_predicted_probobility[:,1].round(4)\n",
    "        else:\n",
    "            print(\"columns of y_predicted_probobility is: \",len(y_predicted_probobility[0]))\n",
    "            y_predicted_probobility =  y_predicted_probobility.round(4)\n",
    "        #print(y_labels)      \n",
    "        auroc, auprc, physio_accuracy, f_measure, utility_score = evaluate_performance(y_labels, y_predicted, y_predicted_probobility,patientID_ytest)\n",
    "        auroc_model.append(round(auroc,4))\n",
    "        auprc_model.append(round(auprc,4))\n",
    "        physio_accuracy_model.append(round(physio_accuracy,4))\n",
    "        f_measure_model.append(round(f_measure,4))\n",
    "        utility_score_model.append(round(utility_score,4))\n",
    "        positivepredictions.append(np.sum(y_predicted))\n",
    "        predictionsRatio.append(np.sum(y_predicted)/np.sum(y_test))\n",
    "        horizontal_stack = pd.concat([y_test, y_predicted], axis=1)\n",
    "\n",
    "\n",
    "        #take down the results\n",
    "        accuracy_model.append((accuracy_score(y_test, y_predicted, normalize=True)*100).round(2))\n",
    "        F1Score_model.append((f1_score(y_test, y_predicted)*100).round(2))\n",
    "        baseline_model.append(round( (1 - float(y_test.mean()) )*100 , 2 ))\n",
    "        print(\"\\ny_test size:\",y_test.shape, '1´s in y_test',y_test.sum())\n",
    "        #baseline_model.append(((1-y_test.mean())*100).round(2))\n",
    "        print(\"The number of 1 (SepsisLabel) in this prediction: \", np.sum(y_predicted))\n",
    "        end1 = time.time()\n",
    "        print(\"Time spent in this KFold iteration\",round(end1-start1,2),\"sec.\\n\")\n",
    "        print(\"******************************************************************\")\n",
    "    print('Accuracy model:', accuracy_model)\n",
    "    print('F1_score model:', F1Score_model)\n",
    "    print('Baseline model:', baseline_model)\n",
    "    \n",
    "    print(\"\\nEvaluation parameters of the utiltiy evaluation function:\")\n",
    "    print('auroc of model:', auroc_model)\n",
    "    print('auprc of model:', auprc_model)\n",
    "    print('Utility accuracy of model:', accuracy_model)\n",
    "    print('utility F1 of model:', f_measure_model)\n",
    "    print('Utility score of model:', utility_score_model)\n",
    "    \n",
    "    KNN_UtilityScore_mean.append(np.mean(utility_score_model))\n",
    "    KNN_UtilityScore_std.append(np.std(utility_score_model))\n",
    "    \n",
    "    KNN_F1Score_mean.append(np.mean(f_measure_model))\n",
    "    KNN_F1Score_std.append(np.std(f_measure_model))\n",
    "    \n",
    "    KNN_auroc_mean.append(np.mean(auroc_model))\n",
    "    KNN_auprc_mean.append(np.mean(auprc_model))\n",
    "    \n",
    "    KNN_accuracy_mean.append(np.mean(physio_accuracy_model))\n",
    "    KNN_accuracy_std.append(np.std(physio_accuracy_model))\n",
    "    \n",
    "    KNN_positiveprediction_mean.append(np.mean(positivepredictions))\n",
    "    KNN_sepsisLabelRatio_mean.append(np.mean(predictionsRatio))\n",
    "\n",
    "    KNN_baseline_mean.append(np.mean(baseline_model))\n",
    "    totalTime=round(time.time()- start,2)\n",
    "    KNN_total_Time.append(totalTime)\n",
    "    \n",
    "    print(\"\\nTotal Time spent in  KFold function\",totalTime,\"sec.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Print_DATA():\n",
    "    print(\"KNN_UtilityScore_mean\",KNN_UtilityScore_mean)\n",
    "    print(\"KNN_UtilityScore_std\",KNN_UtilityScore_std)\n",
    "    print(\"KNN_F1Score_mean\",KNN_F1Score_mean)\n",
    "    print(\"KNN_F1Score_std\",KNN_F1Score_std)\n",
    "    print(\"KNN_auroc_mean\",KNN_auroc_mean)\n",
    "    print(\"KNN_auprc_mean\",KNN_auprc_mean)\n",
    "    print(\"KNN_accuracy_mean\",KNN_accuracy_mean)\n",
    "    print(\"KNN_accuracy_std\",KNN_accuracy_std)\n",
    "    print(\"KNN_positiveprediction_mean\",KNN_positiveprediction_mean)\n",
    "    print(\"KNN_sepsisLabelRatio_mean\", KNN_sepsisLabelRatio_mean)\n",
    "    print(\"KNN_baseline_mean\",KNN_baseline_mean)\n",
    "    print(\"KNN_total_time\",KNN_total_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is how to train the model\n",
    "#logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='saga', max_iter=1000,penalty='l1')\n",
    "logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='lbfgs', max_iter=1000)\n",
    "decisionTreeModel = tree.DecisionTreeClassifier(random_state=2)\n",
    "randomForestModel = RandomForestClassifier(random_state=2)\n",
    "XGBoostModel = XGBClassifier(random_state=2)\n",
    "#AdaBoostModel = AdaBoostClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../raw_data/raw_data_400.csv\n",
      "Data isn´t all filled before K-Fold Func\n"
     ]
    }
   ],
   "source": [
    "#fill the missing data with one function\n",
    "print(filename)\n",
    "#print(originalData)\n",
    "if (originalData.isnull().values.any()):\n",
    "    print('Data isn´t all filled before K-Fold Func')\n",
    "#data,fillmethod = flib.linearFillingAll(originalData,1, True)#forwardfilling + fill other missing data with 0\n",
    "#dataByPatient = data.groupby('Patient_id') # data grouped by Patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2',\n",
       "       'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN',\n",
       "       'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
       "       'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
       "       'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
       "       'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2',\n",
       "       'HospAdmTime', 'ICULOS', 'SepsisLabel', 'Patient_id', 'time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "originalData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR                   9.727652\n",
      "O2Sat               12.816002\n",
      "Temp                65.930414\n",
      "SBP                 14.255929\n",
      "MAP                 11.825645\n",
      "DBP                 30.453479\n",
      "Resp                15.461298\n",
      "EtCO2               95.810529\n",
      "BaseExcess          94.344540\n",
      "HCO3                95.934324\n",
      "FiO2                92.194423\n",
      "pH                  93.067501\n",
      "PaCO2               94.377118\n",
      "SaO2                96.631483\n",
      "AST                 98.175658\n",
      "BUN                 93.158718\n",
      "Alkalinephos        98.201720\n",
      "Calcium             94.513943\n",
      "Chloride            95.706281\n",
      "Creatinine          93.888455\n",
      "Bilirubin_direct    99.765442\n",
      "Glucose             82.870732\n",
      "Lactate             97.419859\n",
      "Magnesium           93.738598\n",
      "Phosphate           96.097211\n",
      "Potassium           90.819651\n",
      "Bilirubin_total     98.377639\n",
      "TroponinI           98.996612\n",
      "Hct                 91.132395\n",
      "Hgb                 92.611415\n",
      "PTT                 97.061506\n",
      "WBC                 93.575710\n",
      "Fibrinogen          99.400573\n",
      "Platelets           93.979672\n",
      "Age                  0.000000\n",
      "Gender               0.000000\n",
      "Unit1               37.516289\n",
      "Unit2               37.516289\n",
      "HospAdmTime          0.000000\n",
      "ICULOS               0.000000\n",
      "SepsisLabel          0.000000\n",
      "Patient_id           0.000000\n",
      "time                 0.000000\n",
      "dtype: float64\n",
      "['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'Glucose', 'Age', 'Gender', 'Unit1', 'Unit2', 'HospAdmTime', 'ICULOS', 'SepsisLabel', 'Patient_id', 'time']\n",
      "(17,)\n",
      "['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'Glucose', 'Age', 'Gender', 'Unit1', 'Unit2', 'HospAdmTime', 'ICULOS', 'SepsisLabel', 'Patient_id', 'time']\n",
      "      HR  O2Sat  Temp    SBP    MAP  DBP  Resp  Glucose    Age  Gender  Unit1  \\\n",
      "0    NaN    NaN   NaN    NaN    NaN  NaN   NaN      NaN  83.14       0    NaN   \n",
      "1   97.0   95.0   NaN   98.0  75.33  NaN  19.0      NaN  83.14       0    NaN   \n",
      "2   89.0   99.0   NaN  122.0  86.00  NaN  22.0      NaN  83.14       0    NaN   \n",
      "3   90.0   95.0   NaN    NaN    NaN  NaN  30.0      NaN  83.14       0    NaN   \n",
      "4  103.0   88.5   NaN  122.0  91.33  NaN  24.5      NaN  83.14       0    NaN   \n",
      "\n",
      "   Unit2  HospAdmTime  ICULOS  SepsisLabel  Patient_id  time  \n",
      "0    NaN        -0.03       1            0           1     0  \n",
      "1    NaN        -0.03       2            0           1     1  \n",
      "2    NaN        -0.03       3            0           1     2  \n",
      "3    NaN        -0.03       4            0           1     3  \n",
      "4    NaN        -0.03       5            0           1     4  \n"
     ]
    }
   ],
   "source": [
    "missing = originalData.isna().sum()*100/len(originalData)\n",
    "print(missing)\n",
    "\n",
    "cols=list(missing[missing<90].index)\n",
    "print(cols)\n",
    "print(np.shape(cols))\n",
    "col = cols.copy()\n",
    "print(col)\n",
    "X_columns = col\n",
    "data=originalData[cols]\n",
    "print(data.head())\n",
    "\n",
    "dataByPatient = data.groupby('Patient_id') # data grouped by Patient_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasize 400\n",
      "K Fold of  10  folds with KNN = 5\n",
      "for the 1 th iteration [ 74 171 275 215 388 212 112 226  61 252 232 312 105  66 143 199 270  27\n",
      " 343 237 380 324  57 247 274 266 373  89 283  85 156 188  39  43   4 272\n",
      " 213  91 299 323]\n",
      "Time for splitting id to test: 0.0\n",
      "Time for splitting id to train: 0.0\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-b49a7d0d3cfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# print(\"Logistic Regression\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mKFold_patient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecisionTreeModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-028324d1394c>\u001b[0m in \u001b[0;36mKFold_patient\u001b[1;34m(model, KforKFold, KforKNN, fillmethod)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mpositivepredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mpredictionsRatio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_predicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mhorizontal_stack\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_predicted\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \"\"\"\n\u001b[1;32m--> 274\u001b[1;33m     op = _Concatenator(\n\u001b[0m\u001b[0;32m    275\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[0;32m    357\u001b[0m                     \u001b[1;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m                 )\n\u001b[1;32m--> 359\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m             \u001b[1;31m# consolidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'numpy.ndarray'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "# print(\"Logistic Regression\")\n",
    "KFold_patient(decisionTreeModel,10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Print_DATA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Logistic Regression\")\n",
    "KFold_patient(XGBoostModel,10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Fold of  10  folds with KNN = 5\n",
      "for the 1 th iteration [ 74 171 275 215 388 212 112 226  61 252 232 312 105  66 143 199 270  27\n",
      " 343 237 380 324  57 247 274 266 373  89 283  85 156 188  39  43   4 272\n",
      " 213  91 299 323]\n",
      "Time for splitting id to test: 0.66\n",
      "Time for splitting id to train: 22.18\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (1405, 1) 1´s in y_test SepsisLabel    49.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  49\n",
      "Time spent in this KFold iteration 72.06 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 2 th iteration [285  63 302 288 164 256  67 160 240 138 179 307 150 242 391   8 169 118\n",
      " 356 394 222  19 332 261 392 124  10 139 235 140   5  41 244 385  17 330\n",
      " 358 314 165 289]\n",
      "Time for splitting id to test: 0.31\n",
      "Time for splitting id to train: 4.81\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (1401, 1) 1´s in y_test SepsisLabel    20.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  20\n",
      "Time spent in this KFold iteration 55.63 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 3 th iteration [382  12  34  25 268   3 301 399 196 347 231 352 374 328 304 202  64  48\n",
      "  26  68 350 357 142 178  96 204 144 109 187  47 221 337  81 383 375  35\n",
      " 397 123 103 246]\n",
      "Time for splitting id to test: 0.37\n",
      "Time for splitting id to train: 5.37\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (1520, 1) 1´s in y_test SepsisLabel    48.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  48\n",
      "Time spent in this KFold iteration 53.01 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 4 th iteration [ 38 276 106 349 335  15 341 245 331 369 327 344  69 326 130 241 126 151\n",
      " 110 205 279 334 313 321 170  53  80  97 158 309 172 197 163  92  78 365\n",
      " 173  95 389 141]\n",
      "Time for splitting id to test: 0.42\n",
      "Time for splitting id to train: 5.4\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (1767, 1) 1´s in y_test SepsisLabel    40.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  40\n",
      "Time spent in this KFold iteration 54.59 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 5 th iteration [167 189 162 284 292 310  21 366 191  75 360 201 216 134 379 135 291 367\n",
      " 395 230 316 181 129 192 239 136 338 253 168   6 157 257 182   2 211 317\n",
      " 220  29 115  13]\n",
      "Time for splitting id to test: 0.31\n",
      "Time for splitting id to train: 4.7\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (1688, 1) 1´s in y_test SepsisLabel    6.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  6\n",
      "Time spent in this KFold iteration 47.07 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 6 th iteration [ 51 293 336 400  93 101 145 355 184  24 186 132 305 218 264 342 116 269\n",
      " 238  28  32 263  40 296 122 208 376  58 155  52  22  31 114 111  87 377\n",
      " 353 149 281 378]\n",
      "Time for splitting id to test: 0.32\n",
      "Time for splitting id to train: 4.88\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (1554, 1) 1´s in y_test SepsisLabel    28.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  28\n",
      "Time spent in this KFold iteration 47.46 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 7 th iteration [287 223 227 315 322 225 386  54 128 278 166   1  94 248  84 180 290  62\n",
      " 362 175 282   9  98 345 319 384 259  79 185 371  55 393 303  49 148  36\n",
      "  42 348 370 229]\n",
      "Time for splitting id to test: 0.34\n",
      "Time for splitting id to train: 4.64\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (1852, 1) 1´s in y_test SepsisLabel    39.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  39\n",
      "Time spent in this KFold iteration 47.64 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 8 th iteration [210  72 119 224  88 306 368 387 295 154  83 104  14  86  60 203  90 214\n",
      " 153 398 131 217  18 372 346 176 152   7 125 177 113 280 390  37 262 146\n",
      " 271 325  77 159]\n",
      "Time for splitting id to test: 0.32\n",
      "Time for splitting id to train: 5.16\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (1406, 1) 1´s in y_test SepsisLabel    17.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  17\n",
      "Time spent in this KFold iteration 51.82 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 9 th iteration [102 320 258 381 351 161 273 364 308  82  70 219 183 286 147 228 300 234\n",
      " 297  76 100 251  20 277 363 311  73 298 107 265 333 255  45 354 121 174\n",
      "  30 339  56 194]\n",
      "Time for splitting id to test: 0.32\n",
      "Time for splitting id to train: 4.79\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (1239, 1) 1´s in y_test SepsisLabel    54.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  54\n",
      "Time spent in this KFold iteration 55.68 sec.\n",
      "\n",
      "******************************************************************\n",
      "for the 10 th iteration [318 198  33  50 133 340  59 195 243 209 267 137 359  11 120 249  46 207\n",
      " 396 294 254 200 233 250 236  16 329 206 108 260 127  71  44  23 361  99\n",
      "  65 193 190 117]\n",
      "Time for splitting id to test: 0.33\n",
      "Time for splitting id to train: 5.29\n",
      "X_train or X_test contains NaN values, KNN/mean is performed.\n",
      "X_train_impute or X_test_impute have all been filled \n",
      "\n",
      "y_test size: (1516, 1) 1´s in y_test SepsisLabel    20.0\n",
      "dtype: float64\n",
      "The number of 1 (SepsisLabel) in this prediction:  20\n",
      "Time spent in this KFold iteration 46.74 sec.\n",
      "\n",
      "******************************************************************\n",
      "Accuracy model: [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "F1_score model: [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "Baseline model: [96.51, 98.57, 96.84, 97.74, 99.64, 98.2, 97.89, 98.79, 95.64, 98.68]\n",
      "\n",
      "Evaluation parameters of the utiltiy evaluation function:\n",
      "auroc of model: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "auprc of model: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Utility accuracy of model: [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
      "utility F1 of model: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "Utility score of model: [0.8538, 0.8612, 0.882, 0.8571, 0.7541, 0.8916, 0.8529, 0.9061, 0.8865, 0.8571]\n",
      "\n",
      "Total Time spent in  KFold function 531.7 sec.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(\"Logistic Regression\")\n",
    "KFold_patient(XGBoostModel,10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN_UtilityScore_mean [0.8763799999999999, 0.8763799999999999]\n",
      "KNN_UtilityScore_std [0.04571071646780435, 0.04571071646780435]\n",
      "KNN_F1Score_mean [1.0, 1.0]\n",
      "KNN_F1Score_std [0.0, 0.0]\n",
      "KNN_auroc_mean [0.0, 1.0]\n",
      "KNN_auprc_mean [0.0, 1.0]\n",
      "KNN_accuracy_mean [1.0, 1.0]\n",
      "KNN_accuracy_std [0.0, 0.0]\n",
      "KNN_positiveprediction_mean [22.7, 22.7]\n",
      "KNN_baseline_mean [97.124, 97.124]\n",
      "KNN_total_time [113.18, 127.0]\n"
     ]
    }
   ],
   "source": [
    "Print_DATA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop features with 90% missing (decisionTreee)\n",
    "# Accuracy model: [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
    "# F1_score model: [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
    "# Baseline model: [98.47, 97.58, 98.21, 95.94, 98.42, 98.48, 95.81, 95.2, 98.54, 94.59]\n",
    "\n",
    "# Evaluation parameters of the utiltiy evaluation function:\n",
    "# auroc of model: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "# auprc of model: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "# Utility accuracy of model: [100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0]\n",
    "# utility F1 of model: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "# Utility score of model: [1.0, 0.9126, 0.8344, 0.8503, 0.8654, 0.8571, 0.8515, 0.8783, 0.8571, 0.8571]\n",
    "\n",
    "# Total Time spent in  KFold function 113.18 sec.\n",
    "# KNN_UtilityScore_mean [0.8763799999999999]\n",
    "# KNN_UtilityScore_std [0.04571071646780435]\n",
    "# KNN_F1Score_mean [1.0]\n",
    "# KNN_F1Score_std [0.0]\n",
    "# KNN_auroc_mean [0.0]\n",
    "# KNN_auprc_mean [0.0]\n",
    "# KNN_accuracy_mean [1.0]\n",
    "# KNN_accuracy_std [0.0]\n",
    "# KNN_positiveprediction_mean [22.7]\n",
    "# KNN_baseline_mean [97.124]\n",
    "# KNN_total_time [113.18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN_UtilityScore_mean [0.10571]\n",
      "KNN_UtilityScore_std [0.13807516395065406]\n",
      "KNN_F1Score_mean [0.10476]\n",
      "KNN_F1Score_std [0.10757065770924709]\n",
      "KNN_auroc_mean [0.0]\n",
      "KNN_auprc_mean [0.0]\n",
      "KNN_accuracy_mean [0.9001999999999999]\n",
      "KNN_accuracy_std [0.07986740261207949]\n",
      "KNN_positiveprediction_mean [75.8]\n",
      "KNN_baseline_mean [97.124]\n",
      "KNN_total_time [134.2]\n"
     ]
    }
   ],
   "source": [
    "Print_DATA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 200\n",
    "\n",
    "# Accuracy model: [94.39, 89.65, 77.34, 83.25, 93.85, 93.94, 88.73, 92.87, 97.38, 91.34]\n",
    "# F1_score model: [0.0, 2.53, 5.58, 2.94, 0.0, 0.0, 18.75, 24.66, 0.0, 11.11]\n",
    "# Baseline model: [98.47, 97.58, 98.21, 95.94, 98.42, 98.48, 95.81, 95.2, 98.54, 94.59]\n",
    "\n",
    "# Evaluation parameters of the utiltiy evaluation function:\n",
    "# auroc of model: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "# auprc of model: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "# Utility accuracy of model: [94.39, 89.65, 77.34, 83.25, 93.85, 93.94, 88.73, 92.87, 97.38, 91.34]\n",
    "# utility F1 of model: [0.0, 0.0253, 0.0558, 0.0294, 0.0, 0.0, 0.1875, 0.2466, 0.0, 0.1111]\n",
    "# Utility score of model: [-0.0923, -0.0583, 0.0301, -0.0208, -0.0837, -0.0857, 0.2554, 0.2509, -0.0229, 0.0562]\n",
    "\n",
    "# Total Time spent in  KFold function 305.26 sec.\n",
    "\n",
    "\n",
    "# Accuracy model: [94.39, 89.65, 77.34, 83.25, 93.85, 93.94, 88.73, 92.87, 97.38, 91.34]\n",
    "# F1_score model: [0.0, 2.53, 5.58, 2.94, 0.0, 0.0, 18.75, 24.66, 0.0, 11.11]\n",
    "# Baseline model: [98.47, 97.58, 98.21, 95.94, 98.42, 98.48, 95.81, 95.2, 98.54, 94.59]\n",
    "\n",
    "# Evaluation parameters of the utiltiy evaluation function:\n",
    "# auroc of model: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "# auprc of model: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "# Utility accuracy of model: [94.39, 89.65, 77.34, 83.25, 93.85, 93.94, 88.73, 92.87, 97.38, 91.34]\n",
    "# utility F1 of model: [0.0, 0.0253, 0.0558, 0.0294, 0.0, 0.0, 0.1875, 0.2466, 0.0, 0.1111]\n",
    "# Utility score of model: [-0.0923, -0.0583, 0.0301, -0.0208, -0.0837, -0.0857, 0.2554, 0.2509, -0.0229, 0.0562]\n",
    "\n",
    "# Total Time spent in  KFold function 109.83 sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Decision tree\")\n",
    "#KFold_patient(randomForestModel,10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findBestKforKNN(logisticRegressionModel,10,1,10)\n",
    "# findBestKforKNN(XGBoostModel,10,110,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# findBestKforKNN(decisionTreeModel,10,1,10)\n",
    "# os.system('\\a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'displayCurrentResult' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-6ff9340e467f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplayCurrentResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'displayCurrentResult' is not defined"
     ]
    }
   ],
   "source": [
    "displayCurrentResult(1,9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
