{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the code to find the most suitable K value for the KNN filling algorithm\n",
    "Since Logistic regression performs and worst among all algorithm, we don't use it here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "# Cross Validation Classification Accuracy\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing \n",
    "from sklearn.impute import KNNImputer\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "#import faiss\n",
    "from numpy import isnan\n",
    "#import matplotlib.pyplot as plot\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn import tree\n",
    "import statistics\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# plotting errorbar graph for visual representation of the performance of the classifiers\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import Affine2D\n",
    "import random\n",
    "from xgboost import XGBClassifier\n",
    "import shutil\n",
    "import os\n",
    "from os import path\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "# import ipynb.fs.full.our_functions_library as flib\n",
    "from our_evaluate_sepsis_score import evaluate_performance\n",
    "# from our_functions_library import *\n",
    "import our_functions_library as flib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e6721666ec5f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../../raw_data/raw_data_1000.csv'\u001b[0m \u001b[1;31m# use raw dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#filename = 'data.csv' # use raw dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0moriginalData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# read csv data into DataFrame var raw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data size:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moriginalData\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mOriginal_Uniq_ID\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginalData\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Patient_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_csv' is not defined"
     ]
    }
   ],
   "source": [
    "# Global initialization, get all the data from file and generate all the needed variable\n",
    "filename = '../../raw_data/raw_data_1000.csv' # use raw dataset\n",
    "#filename = 'data.csv' # use raw dataset\n",
    "originalData = pd.read_csv(filename) # read csv data into DataFrame var raw\n",
    "print(\"Data size:\",originalData.shape)\n",
    "Original_Uniq_ID= np.unique(originalData['Patient_id']) \n",
    "Uniq_ID = Original_Uniq_ID.copy()\n",
    "print('Patient id size:',len(Uniq_ID))\n",
    "X_columns = ['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2','BaseExcess', 'HCO3', 'FiO2', 'pH', \n",
    "             'PaCO2', 'SaO2', 'AST', 'BUN','Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
    "             'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium','Bilirubin_total', 'TroponinI', 'Hct', \n",
    "             'Hgb', 'PTT', 'WBC','Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2','HospAdmTime',\n",
    "             'ICULOS', 'Patient_id', 'time']\n",
    "y_columns = ['Patient_id', 'SepsisLabel']\n",
    "\n",
    "# To test if these 3 columns is useful\n",
    "# originalData = originalData.drop(['Unit1', 'Unit2', 'EtCO2'], axis=1)\n",
    "# X_columns.remove('Unit1')\n",
    "# X_columns.remove( 'Unit2')\n",
    "# X_columns.remove( 'EtCO2')\n",
    "\n",
    "# Initialize the empty array X_train, X_test, y_train, y_test\n",
    "X_train = pd.DataFrame(columns = X_columns)\n",
    "X_test = pd.DataFrame(columns = X_columns)\n",
    "y_train = pd.DataFrame(columns = y_columns)\n",
    "y_test = pd.DataFrame(columns = y_columns)\n",
    "# Below are the lists for KNN results\n",
    "\n",
    "KNN_UtilityScore_mean = []\n",
    "KNN_UtilityScore_std = []\n",
    "\n",
    "KNN_F1Score_mean = []\n",
    "KNN_F1Score_std = []\n",
    "\n",
    "KNN_auroc_mean = []\n",
    "KNN_auprc_mean = []\n",
    "\n",
    "KNN_accuracy_mean = []\n",
    "KNN_accuracy_std = []\n",
    "\n",
    "KNN_positiveprediction_mean = []\n",
    "KNN_baseline_mean = [ ]\n",
    "\n",
    "KNN_total_Time= [ ]\n",
    "\n",
    "\n",
    "fillmethod =\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This block will shuffle the id sets of patients in a fix manner, so for every time you run the code, the dataset and trainset are always the same.\n",
    "seed = 2\n",
    "random.seed(seed)\n",
    "if(np.array_equal(Original_Uniq_ID,Uniq_ID) ):\n",
    "    print(\"They are the same. Uniq id hasn't been shuffled, and it will be shuffeld now.\")   \n",
    "    random.shuffle(Uniq_ID)# randomly sorted the patient IDs    \n",
    "else:\n",
    "    print(\"They are not the same. Uniq_id has already been shuffled.\")    \n",
    "print(\"The original uniq id set is:\\n\",Original_Uniq_ID[1:20])\n",
    "print(\"Uniq id:************************************\")\n",
    "print(\"The fixed shuffelld id set, it should be 211 275 153 189 184 110 124  49 345...\\n\",Uniq_ID[1:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDataset():\n",
    "    print('X train shape:',X_train.shape)\n",
    "    print(X_train)\n",
    "    print( 'Y train shape:',y_train.shape)\n",
    "    print(y_train)\n",
    "    print('X test shape:',X_test.shape)\n",
    "    print(X_test)\n",
    "    print( 'Y test shape:',y_test.shape)\n",
    "    print(y_test)\n",
    "    \n",
    "def clearAllDatasets():\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    if not X_train.empty: \n",
    "        X_train = X_train[0:0]\n",
    "    if not X_test.empty:\n",
    "        X_test = X_test[0:0]\n",
    "    if not y_train.empty:\n",
    "        y_train = y_train[0:0]\n",
    "    if not y_test.empty:\n",
    "        y_test = y_test[0:0]\n",
    "        \n",
    "def KNN_reset():\n",
    "    #KNN with different K size, \n",
    "    KNN_UtilityScore_mean.clear()\n",
    "    KNN_UtilityScore_std.clear()\n",
    "    KNN_F1Score_mean.clear()\n",
    "    KNN_F1Score_std.clear()\n",
    "    KNN_auroc_mean.clear()\n",
    "    KNN_auprc_mean.clear()\n",
    "    KNN_accuracy_mean.clear()\n",
    "    KNN_accuracy_std.clear()\n",
    "    KNN_positiveprediction_mean.clear()\n",
    "    KNN_baseline_mean.clear()\n",
    "    KNN_total_Time.clear()\n",
    "    \n",
    "def generateTrainDataSet(patienIds):\n",
    "    global X_train, y_train\n",
    "    for i in patienIds:\n",
    "#     print('Patient_id',i,':\\n',dataByPatient.get_group(i),'\\n')\n",
    "        X_train = X_train.append(dataByPatient.get_group(i).loc[:, X_columns])\n",
    "        y_train = y_train.append(dataByPatient.get_group(i).loc[:, y_columns])\n",
    "    return X_train, y_train\n",
    " \n",
    "def generateTestDataSet(patienIds):\n",
    "    global X_test, y_test\n",
    "    for i in patienIds:\n",
    "#     print('Patient_id',i,':\\n',dataByPatient.get_group(i),'\\n')\n",
    "        X_test = X_test.append(dataByPatient.get_group(i).loc[:, X_columns])\n",
    "        y_test = y_test.append(dataByPatient.get_group(i).loc[:, y_columns]) \n",
    "    return X_test, y_test\n",
    "\n",
    "# def CalculateSOFAScore(X_train_impute, X_test_impute):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for K-fold algorithm, Before this step the missing data has been filled, \n",
    "def KFold_patient(model, KforKFold=10,KforKNN=5, fillmethod=\"\"):\n",
    "    start = time.time()# time indicator for how long the Kfold func takes\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    print(\"K Fold of \",KforKFold ,\" folds with KNN =\",KforKNN)\n",
    "    \n",
    "    # initialisation of the array for storing the different intermediate results\n",
    "    accuracy_model = []\n",
    "    F1Score_model = []\n",
    "    baseline_model= []\n",
    "    auroc_model = []\n",
    "    auprc_model = []\n",
    "    physio_accuracy_model = []\n",
    "    f_measure_model = []\n",
    "    utility_score_model = []\n",
    "    mean_train = 0\n",
    "    positivepredictions = []\n",
    "    #The unique id sets have been created and shuffled in a fix manner in the third block, you can just use it here and no more any other manipulation\n",
    "    idSets = np.array_split(Uniq_ID, KforKFold)# divide the ids into K groups\n",
    "    #print(\"Patients number: \", len(Uniq_ID)) #print('idSets arrays',idSets)\n",
    "    #This for loop is for Kfold, calculating the results for K times\n",
    "    for i in range(KforKFold):\n",
    "        start1 = time.time()\n",
    "        clearAllDatasets()\n",
    "#         X_train, X_test, y_train, y_test = flib.clearAllDatasets(X_train, X_test, y_train, y_test) #first clear all the datasets\n",
    "        print(\"for the\",i+1,\"th iteration\",idSets[i])   \n",
    "        t1 = time.time()\n",
    "        X_test,y_test = generateTestDataSet(idSets[i])\n",
    "        print(\"Time for splitting id to test:\", round(time.time()- t1,2))\n",
    "        \n",
    "        t2= time.time()\n",
    "        for j in range(KforKFold):\n",
    "            if j != i:\n",
    "                 X_train, y_train = generateTrainDataSet(idSets[j])\n",
    "        print(\"Time for splitting id to train:\", round(time.time()- t2,2))\n",
    "\n",
    "        #printDataset()\n",
    "        #Now the train and test dataset is generated\n",
    "        #we can begin to train the model wit the training set and evaaulate the performance with the test sett   \n",
    "#         X_train = X_train.drop('time', 1) X_test = X_test.drop('time', 1)\n",
    "        X_train=X_train.astype('float64')\n",
    "        X_test=X_test.astype('float64')    \n",
    "        YTest_copy = y_test  # variable of joining the filled data (X) and Y (Train_output) \n",
    "        patientID_ytest = y_test['Patient_id']\n",
    "        y_train = y_train.drop('Patient_id', 1)\n",
    "        y_test = y_test.drop('Patient_id', 1)      \n",
    "        y_train=y_train.astype('float64')\n",
    "        y_test=y_test.astype('float64')\n",
    "        #print('YTest',YTest_copy.head())\n",
    "        \n",
    "        #fill the missing data\n",
    "        if X_train.isnull().values.any() or X_test.isnull().values.any() :\n",
    "            print(\"X_train or X_test contains NaN values, KNN/mean is performed.\")\n",
    "            #if there is missing value\n",
    "            X_train_impute, X_test_impute, fillmethod = flib.KNNfilling(X_train, X_test, KforKNN, fillmethod)\n",
    "            #X_train_impute, X_test_impute,fillmethod = flib.MeanFilling(X_train,X_test, fillmethod)\n",
    "            #check the missing data   \n",
    "            if np.isnan(X_train_impute).any() or np.isnan(X_test_impute).any() :\n",
    "                print(\"X_train_impute or X_test_impute still contains NaN values\")        \n",
    "            else:\n",
    "                print(\"X_train_impute or X_test_impute have all been filled \")  \n",
    "        else:\n",
    "            print(\"X_train or X_test have all been filled \")\n",
    "            X_train_impute = X_train\n",
    "            X_test_impute = X_test\n",
    "                 \n",
    "        #Scale the data， uncomment this part for logistic regression only, in other case, put them in comment\n",
    "        model_name = type(model).__name__\n",
    "        if (model_name == 'LogisticRegression'):\n",
    "            print(\"scaled!\")\n",
    "            scaler = preprocessing.StandardScaler()\n",
    "            scaler.fit(X_train_impute)\n",
    "            X_train_impute = scaler.transform(X_train_impute)\n",
    "            X_test_impute = scaler.transform(X_test_impute)\n",
    "\n",
    "        #fit the model and predict\n",
    "        model.fit(X_train_impute, y_train)\n",
    "        y_predicted = model.predict(X_test_impute)   \n",
    "        y_predicted_probobility = model.predict_proba(X_test_impute) \n",
    "        #transfer the outpu and evalute it\n",
    "        y_labels = y_test.astype(int).to_numpy()\n",
    "        y_predicted = y_predicted.astype(int)\n",
    "        y_predicted_probobility =  y_predicted_probobility[:,1].round(4)\n",
    "        #print(y_labels)      \n",
    "        auroc, auprc, physio_accuracy, f_measure, utility_score = evaluate_performance(y_labels, y_predicted, y_predicted_probobility,patientID_ytest)\n",
    "#         print(\"\\nauroc\",round(auroc,4),\"auprc\",round(auprc,4),\"util_accuracy\",round(accuracy1,4))\n",
    "#         print(\"f_measure\",round(f_measure,4),\"utility_score\",round(utility_score,4))  \n",
    "        auroc_model.append(round(auroc,4))\n",
    "        auprc_model.append(round(auprc,4))\n",
    "        physio_accuracy_model.append(round(physio_accuracy,4))\n",
    "        f_measure_model.append(round(f_measure,4))\n",
    "        utility_score_model.append(round(utility_score,4))\n",
    "        positivepredictions.append(np.sum(y_predicted))\n",
    "\n",
    "        num_rows= X_test_impute.shape[0]\n",
    "        scores = np.zeros(num_rows).astype('float64')# score parameter:output from get_sepsis_score\n",
    "        labels = np.zeros(num_rows).astype('float64')\n",
    "        #WriteToFiles(X_train_impute,YTest_copy,i, fillmethod)\n",
    "        #CalcMean_Std(X_train_impute)\n",
    "        #take down the results\n",
    "        accuracy_model.append((accuracy_score(y_test, y_predicted, normalize=True)*100).round(2))\n",
    "        F1Score_model.append((f1_score(y_test, y_predicted)*100).round(2))\n",
    "        baseline_model.append(round( (1 - float(y_test.mean()) )*100 , 2 ))\n",
    "        print(\"\\ny_test size:\",y_test.shape, '1´s in y_test',y_test.sum())\n",
    "        #baseline_model.append(((1-y_test.mean())*100).round(2))\n",
    "        print(\"The number of 1 (SepsisLabel) in this prediction: \", np.sum(y_predicted))\n",
    "        end1 = time.time()\n",
    "        print(\"Time spent in this KFold iteration\",round(end1-start1,2),\"sec.\\n\")\n",
    "        print(\"******************************************************************\")\n",
    "    print('Accuracy model:', accuracy_model)\n",
    "    print('F1_score model:', F1Score_model)\n",
    "    print('Baseline model:', baseline_model)   \n",
    "    print(\"\\nEvaluation parameters of the utiltiy evaluation function:\")\n",
    "    print('auroc of model:', auroc_model)\n",
    "    print('auprc of model:', auprc_model)\n",
    "    print('Utility accuracy of model:', accuracy_model)\n",
    "    print('utility F1 of model:', f_measure_model)\n",
    "    print('Utility score of model:', utility_score_model)\n",
    "    KNN_UtilityScore_mean.append(np.mean(utility_score_model))\n",
    "    KNN_UtilityScore_std.append(np.std(utility_score_model))\n",
    "    KNN_F1Score_mean.append(np.mean(f_measure_model))\n",
    "    KNN_F1Score_std.append(np.std(f_measure_model))\n",
    "    KNN_auroc_mean.append(np.mean(auroc_model))\n",
    "    KNN_auprc_mean.append(np.mean(auprc_model))\n",
    "    KNN_accuracy_mean.append(np.mean(physio_accuracy_model))\n",
    "    KNN_accuracy_std.append(np.std(physio_accuracy_model))\n",
    "    KNN_positiveprediction_mean.append(np.mean(positivepredictions))\n",
    "    KNN_baseline_mean.append(np.mean(baseline_model))\n",
    "    \n",
    "    totalTime=round(time.time()- start,2)\n",
    "    KNN_total_Time.append(totalTime)\n",
    "    print(\"\\nTotal Time spent in  KFold function\",totalTime,\"sec.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def displayCurrentResult(KforKNNstart,KforKNNend):\n",
    "    print(\"KNN_UtilityScore_mean\",KNN_UtilityScore_mean)\n",
    "    print(\"KNN_UtilityScore_std\",KNN_UtilityScore_std)\n",
    "    print(\"KNN_F1Score_mean\",KNN_F1Score_mean)\n",
    "    print(\"KNN_F1Score_std\",KNN_F1Score_std)\n",
    "    print(\"KNN_auroc_mean\",KNN_auroc_mean)\n",
    "    print(\"KNN_auprc_mean\",KNN_auprc_mean)\n",
    "    print(\"KNN_accuracy_mean\",KNN_accuracy_mean)\n",
    "    print(\"KNN_accuracy_std\",KNN_accuracy_std)\n",
    "    print(\"KNN_positiveprediction_mean\",KNN_positiveprediction_mean)\n",
    "    print(\"KNN_baseline_mean\",KNN_baseline_mean)        \n",
    "    print(len(KNN_accuracy_mean))\n",
    "    print(len(KNN_accuracy_std))\n",
    "    print(len(KNN_F1Score_mean))\n",
    "    print(len(KNN_F1Score_std))\n",
    "    print(len(KNN_positiveprediction_mean))\n",
    "#     plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_UtilityScore_mean,\"Mean Utility Score vs K\",xlabel='K',ylabel=\"mean Utility Score\")\n",
    "#     plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_UtilityScore_std,\"std Utility Score vs K\",xlabel='K',ylabel=\"std Utility Score\")\n",
    "#     plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_F1Score_mean,\"Mean F1 score vs K\",xlabel='K',ylabel=\"Mean F1 score\")\n",
    "#     plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_F1Score_std,\"Std F1 score vs K\",xlabel='K',ylabel=\"Std F1 score\")\n",
    "#     plotKNNResultFigure(KforKNNstart,KforKNNend,KNN_accuracy_mean,\"Mean Accuracy vs K\",xlabel='K',ylabel=\"Mean Accuracy\")      \n",
    "def findBestKforKNN(model, KforKFold=10,KforKNNstart=1,KforKNNend=10, stepsize=5):\n",
    "    if(KforKNNend<=1):\n",
    "        print(\"K must be a interger larger than 1\")\n",
    "        return\n",
    "    KNN_reset()\n",
    "    step=stepsize\n",
    "    for i in range(KforKNNstart,KforKNNend+1,step) : \n",
    "        print(\"KNN of K = \",i)    \n",
    "        KFold_patient(model,10,i)\n",
    "    print(\"Now all the training is finished.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is how to train the model\n",
    "#logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='saga', max_iter=1000,penalty='l1')\n",
    "logisticRegressionModel = LogisticRegression(C=0.1,random_state=2,solver='lbfgs', max_iter=1000)\n",
    "decisionTreeModel = tree.DecisionTreeClassifier(random_state=2)\n",
    "randomForestModel = RandomForestClassifier(random_state=2)\n",
    "XGBoostModel = XGBClassifier(random_state=2)\n",
    "#AdaBoostModel = AdaBoostClassifier(random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fill the missing data with one function\n",
    "print(filename)\n",
    "#print(originalData)\n",
    "if (originalData.isnull().values.any()):\n",
    "    print('Data isn´t all filled before K-Fold Func')\n",
    "    data=originalData\n",
    "#data,fillmethod = flib.linearFillingAll(originalData,1, True)#forwardfilling + fill other missing data with 0\n",
    "dataByPatient = data.groupby('Patient_id') # data grouped by Patient_id\n",
    "print(\"Maximum number of processes： \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for 1 fold in Kfold\n",
    "def OneFold_patient_MP(i,model,KforKFold,KforKNN,idSets,fillmethod):\n",
    "    start1 = time.time()\n",
    "    clearAllDatasets()\n",
    "#     X_train, X_test, y_train, y_test = flib.clearAllDatasets(X_train, X_test, y_train, y_test) #first clear all the datasets\n",
    "    print(\"for the\",i+1,\"th iteration\",idSets[i])   \n",
    "    t1 = time.time()\n",
    "    X_test,y_test = generateTestDataSet(idSets[i])\n",
    "    print(\"Time for splitting id to test:\", round(time.time()- t1,2))\n",
    "    t2= time.time()\n",
    "    for j in range(KforKFold):\n",
    "        if j != i:\n",
    "             X_train, y_train = generateTrainDataSet(idSets[j])\n",
    "    print(\"Time for splitting id to train:\", round(time.time()- t2,2))\n",
    "    flib.printDataset(X_train, X_test, y_train, y_test)\n",
    "    #Now the train and test dataset is generated\n",
    "    #we can begin to train the model wit the training set and evaaulate the performance with the test sett   \n",
    "#         X_train = X_train.drop('time', 1) X_test = X_test.drop('time', 1)\n",
    "    X_train=X_train.astype('float64')\n",
    "    X_test=X_test.astype('float64')    \n",
    "    #YTest_copy = y_test  # variable of joining the filled data (X) and Y (Train_output) \n",
    "    patientID_ytest = y_test['Patient_id']\n",
    "    y_train = y_train.drop('Patient_id', 1)\n",
    "    y_test = y_test.drop('Patient_id', 1)      \n",
    "    y_train=y_train.astype('float64')\n",
    "    y_test=y_test.astype('float64')\n",
    "    #print('YTest',YTest_copy.head())\n",
    "\n",
    "    #fill the missing data\n",
    "    if X_train.isnull().values.any() or X_test.isnull().values.any() :\n",
    "        print(\"X_train or X_test contains NaN values, KNN/mean is performed.\")\n",
    "        #if there is missing value\n",
    "        X_train_impute, X_test_impute, fillmethod = flib.KNNfilling(X_train, X_test, KforKNN, fillmethod)\n",
    "        #X_train_impute, X_test_impute,fillmethod = flib.MeanFilling(X_train,X_test, fillmethod)\n",
    "        #check the missing data   \n",
    "        if np.isnan(X_train_impute).any() or np.isnan(X_test_impute).any() :\n",
    "            print(\"X_train_impute or X_test_impute still contains NaN values\")        \n",
    "        else:\n",
    "            print(\"X_train_impute or X_test_impute have all been filled \")  \n",
    "    else:\n",
    "        print(\"X_train or X_test have all been filled \")\n",
    "        X_train_impute = X_train\n",
    "        X_test_impute = X_test\n",
    "    \n",
    "\n",
    "    #Scale the data， uncomment this part for logistic regression only, in other case, put them in comment\n",
    "#     model_name = type(model).__name__\n",
    "#     if (model_name == 'LogisticRegression'):\n",
    "#         print(\"scaled!\")\n",
    "#         scaler = preprocessing.StandardScaler()\n",
    "#         scaler.fit(X_train_impute)\n",
    "#         X_train_impute = scaler.transform(X_train_impute)\n",
    "#         X_test_impute = scaler.transform(X_test_impute)\n",
    "\n",
    "    #fit the model and predict\n",
    "    model.fit(X_train_impute, y_train)\n",
    "    y_predicted = model.predict(X_test_impute)   \n",
    "    y_predicted_probobility = model.predict_proba(X_test_impute) \n",
    "    #transfer the outpu and evalute it\n",
    "    y_labels = y_test.astype(int).to_numpy()\n",
    "    y_predicted = y_predicted.astype(int)\n",
    "    y_predicted_probobility =  y_predicted_probobility[:,1].round(4)\n",
    "    #print(y_labels)      \n",
    "    auroc, auprc, physio_accuracy, f_measure, utility_score = evaluate_performance(y_labels, y_predicted, y_predicted_probobility,patientID_ytest)\n",
    "#         print(\"\\nauroc\",round(auroc,4),\"auprc\",round(auprc,4),\"util_accuracy\",round(accuracy1,4))\n",
    "#         print(\"f_measure\",round(f_measure,4),\"utility_score\",round(utility_score,4))  \n",
    "    result = { \"auroc\": round(auroc,4), \"auprc\": round(auprc,4), \"f_measure\": round(f_measure,4),\n",
    "                \"physio_accuracy\": round(physio_accuracy,4),\"utility_score\": round(utility_score,4), \n",
    "                \"positiveprediction\": np.sum(y_predicted), \n",
    "#         \"accuracy\": (accuracy_score(y_test, y_predicted, normalize=True)*100).round(2), \n",
    "#         \"F1Score\": (f1_score(y_test, y_predicted)*100).round(2),\n",
    "            \"baseline\": round( (1 - float(y_test.mean()) )*100 , 2 )}\n",
    "    \n",
    "    print(\"\\ny_test size:\",y_test.shape, '1´s in y_test',y_test.sum())\n",
    "    \n",
    "    end1 = time.time()\n",
    "    print(\"Time spent in \",i,\"th Fold iteration\",round(end1-start1,2),\"sec.\\n\")\n",
    "    print(\"******************************************************************\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for K-fold algorithm using multi processes\n",
    "def KFold_patient_MP(model, KforKFold=10,KforKNN=5, fillmethod=\"\"):\n",
    "    start = time.time()# time indicator for how long the Kfold func takes\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    print(\"K Fold of \",KforKFold ,\" folds with KNN =\",KforKNN)\n",
    "    # initialisation of the array for storing the different intermediate results\n",
    "    \n",
    "    auroc_model = []\n",
    "    auprc_model = []\n",
    "    f_measure_model = []\n",
    "    physio_accuracy_model = []\n",
    "    utility_score_model = []\n",
    "    positivepredictions = []\n",
    "#     accuracy_model = []\n",
    "#     F1Score_model = []\n",
    "    baseline_model= []\n",
    "    \n",
    "    mean_train = 0\n",
    "    #The unique id sets have been created and shuffled in a fix manner in the third block, you can just use it here and no more any other manipulation\n",
    "    idSets = np.array_split(Uniq_ID, KforKFold)# divide the ids into K groups\n",
    "    #print(\"Patients number: \", len(Uniq_ID)) #print('idSets arrays',idSets)\n",
    "    #This for loop is for Kfold using multi processes\n",
    "    \n",
    "    folds = list(range(0,KforKFold))\n",
    "    \n",
    "#     with ProcessPoolExecutor (max_workers = 10) as executor:  \n",
    "#         results = executor.submit(OneFold_patient_MP, folds)\n",
    "        \n",
    "#         for result in results:\n",
    "#             print(result)\n",
    "\n",
    "    pool = mp.Pool()#here in the parentthses should be 10, but since my mac only has 8, so leave it blank \n",
    "    results = pool.starmap(OneFold_patient_MP, [(fold, model, KforKFold, KforKNN,idSets,fillmethod) for fold in folds])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    for result in results:\n",
    "        auroc_model.append(result[\"auroc\"])\n",
    "        auprc_model.append(result[\"auprc\"])\n",
    "        f_measure_model.append(result[\"f_measure\"])\n",
    "        physio_accuracy_model.append(result[\"physio_accuracy\"])  \n",
    "        utility_score_model.append(result[\"utility_score\"])\n",
    "        positivepredictions.append(result[\"positiveprediction\"])\n",
    "        baseline_model.append(result[\"baseline\"])  \n",
    "        \n",
    "    print(\"\\nEvaluation parameters of the utiltiy evaluation function:\")\n",
    "    print('auroc of model:', auroc_model)\n",
    "    print('auprc of model:', auprc_model)\n",
    "    print('utility F1 of model:', f_measure_model)\n",
    "    print('Utility accuracy of model:', accuracy_model) \n",
    "    print('Utility score of model:', utility_score_model)\n",
    "    print(\"Positive Prediction: \", positivepredictions)\n",
    "    print('Baseline model:', baseline_model)  \n",
    "    KNN_auroc_mean.append(np.mean(auroc_model))\n",
    "    KNN_auprc_mean.append(np.mean(auprc_model))\n",
    "    KNN_F1Score_mean.append(np.mean(f_measure_model))\n",
    "    KNN_F1Score_std.append(np.std(f_measure_model))\n",
    "    KNN_accuracy_mean.append(np.mean(physio_accuracy_model))\n",
    "    KNN_accuracy_std.append(np.std(physio_accuracy_model))\n",
    "    KNN_UtilityScore_mean.append(np.mean(utility_score_model))\n",
    "    KNN_UtilityScore_std.append(np.std(utility_score_model))\n",
    "    KNN_positiveprediction_mean.append(np.mean(positivepredictions))\n",
    "    KNN_baseline_mean.append(np.mean(baseline_model))\n",
    "    \n",
    "    totalTime=round(time.time()- start,2)\n",
    "    KNN_total_Time.append(totalTime)\n",
    "    print(\"\\nTotal Time spent in  KFold function\",totalTime,\"sec.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KFold_patient_MP(decisionTreeModel,10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KFold_patient(decisionTreeModel,10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Logistic Regression\")\n",
    "#KFold_patient(decisionTreeModel,10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Decision tree\")\n",
    "#KFold_patient(randomForestModel,10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findBestKforKNN(logisticRegressionModel,10,1,10)\n",
    "# findBestKforKNN(XGBoostModel,10,110,120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# findBestKforKNN(decisionTreeModel,10,1,10)\n",
    "# os.system('\\a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displayCurrentResult(1,9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
